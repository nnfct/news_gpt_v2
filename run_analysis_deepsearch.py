import os
import requests
import urllib.parse
import time
from datetime import datetime
from dotenv import load_dotenv
from collections import Counter
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
from openai import AzureOpenAI
from error_logger import log_error, auto_log_errors

load_dotenv()

# Azure ì„¤ì •
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_INDEX = os.getenv("AZURE_SEARCH_INDEX")

# DeepSearch API ì„¤ì •
DEEPSEARCH_API_KEY = os.getenv("DEEPSEARCH_API_KEY")

def collect_news():
    """DeepSearch APIë¡œ IT/ê¸°ìˆ  ë¶„ì•¼ 7ì¼ì¹˜ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    if not DEEPSEARCH_API_KEY or DEEPSEARCH_API_KEY == "your_deepsearch_api_key_here":
        print("âš ï¸ DeepSearch API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return [
            {"title": "AI ê¸°ìˆ  ë°œì „ìœ¼ë¡œ ë¯¸ë˜ ì¼ìë¦¬ ë³€í™” ì˜ˆìƒ", "content": "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ê¸‰ì†í•œ ë°œì „ìœ¼ë¡œ ì¸í•´ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ ì¼ìë¦¬ êµ¬ì¡°ì˜ ë³€í™”ê°€ ì˜ˆìƒëœë‹¤ê³  ì „ë¬¸ê°€ë“¤ì´ ë¶„ì„í–ˆë‹¤.", "section": "IT/ê¸°ìˆ ", "url": "https://news.example.com/ai-jobs", "date": "2025-07-18"},
            {"title": "ë°˜ë„ì²´ ì‚°ì—… ì„±ì¥ê³¼ ê¸€ë¡œë²Œ ê²½ìŸë ¥", "content": "êµ­ë‚´ ë°˜ë„ì²´ ê¸°ì—…ë“¤ì´ ì°¨ì„¸ëŒ€ ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ê°œë°œì— ë°•ì°¨ë¥¼ ê°€í•˜ë©° ê¸€ë¡œë²Œ ì‹œì¥ì—ì„œì˜ ê²½ìŸë ¥ì„ ê°•í™”í•˜ê³  ìˆë‹¤.", "section": "IT/ê¸°ìˆ ", "url": "https://news.example.com/semiconductor", "date": "2025-07-17"},
            {"title": "í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì‹œì¥ í™•ëŒ€", "content": "ì½”ë¡œë‚˜19 ì´í›„ ë””ì§€í„¸ ì „í™˜ì´ ê°€ì†í™”ë˜ë©´ì„œ í´ë¼ìš°ë“œ ì»´í“¨íŒ… ì„œë¹„ìŠ¤ ì‹œì¥ì´ ê¸‰ì†íˆ ì„±ì¥í•˜ê³  ìˆë‹¤.", "section": "IT/ê¸°ìˆ ", "url": "https://news.example.com/cloud", "date": "2025-07-16"}
        ]
    
    try:
        news_list = []
        
        # IT/ê¸°ìˆ  ë¶„ì•¼ ì „ë¬¸ í‚¤ì›Œë“œë“¤
        tech_keywords = [
            "ì¸ê³µì§€ëŠ¥", "AI", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹",
            "ë°˜ë„ì²´", "ì¹©", "í”„ë¡œì„¸ì„œ", "ë©”ëª¨ë¦¬",
            "í´ë¼ìš°ë“œ", "ë°ì´í„°ì„¼í„°", "ì„œë²„",
            "ì†Œí”„íŠ¸ì›¨ì–´", "ì•±", "í”Œë«í¼",
            "5G", "6G", "í†µì‹ ", "ë„¤íŠ¸ì›Œí¬",
            "ë¸”ë¡ì²´ì¸", "ì•”í˜¸í™”í", "ë¹„íŠ¸ì½”ì¸",
            "ë©”íƒ€ë²„ìŠ¤", "VR", "AR", "ê°€ìƒí˜„ì‹¤",
            "ë¡œë´‡", "ìë™í™”", "IoT", "ìŠ¤ë§ˆíŠ¸í™ˆ"
        ]
        
        print(f"ğŸ” IT/ê¸°ìˆ  ë¶„ì•¼ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ({len(tech_keywords)}ê°œ í‚¤ì›Œë“œ ì‚¬ìš©)...")
        
        # ê° í‚¤ì›Œë“œë³„ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘
        for keyword in tech_keywords:
            try:
                url = "https://api-v2.deepsearch.com/v1/global-articles"
                params = {
                    "api_key": DEEPSEARCH_API_KEY,
                    "q": keyword,
                    "limit": 10,
                    "start_date": "2025-07-12",  # 7ì¼ ì „
                    "end_date": "2025-07-18",    # ì˜¤ëŠ˜
                    "sort": "published_at:desc"
                }
                
                response = requests.get(url, params=params)
                response.raise_for_status()
                
                data = response.json()
                articles = data.get("articles", [])
                
                for article in articles:
                    title = article.get("title", "")
                    content = article.get("summary", "") or article.get("content", "")
                    url = article.get("url", "")
                    pub_date = article.get("published_at", "")
                    
                    # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                    formatted_date = ""
                    if pub_date:
                        try:
                            if "T" in pub_date:
                                formatted_date = pub_date.split("T")[0]  # YYYY-MM-DD
                            else:
                                formatted_date = pub_date
                        except:
                            formatted_date = "2025-07-18"
                    else:
                        formatted_date = "2025-07-18"
                    
                    # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ì²´í¬
                    is_duplicate = False
                    for existing_news in news_list:
                        if existing_news["title"] == title or existing_news["url"] == url:
                            is_duplicate = True
                            break
                    
                    if not is_duplicate and title and content:
                        news_list.append({
                            "title": title,
                            "content": content,
                            "section": "IT/ê¸°ìˆ ",
                            "url": url,
                            "date": formatted_date
                        })
                
                print(f"  âœ… '{keyword}' í‚¤ì›Œë“œë¡œ {len(articles)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±° í›„ ì¶”ê°€)")
                
                # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ì§§ì€ ì§€ì—°
                time.sleep(0.1)
                
            except Exception as e:
                print(f"  âŒ '{keyword}' í‚¤ì›Œë“œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
        
        print(f"\nâœ… ì´ {len(news_list)}ê°œ IT/ê¸°ìˆ  ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return news_list[:161]  # ìµœëŒ€ 161ê°œë¡œ ì œí•œ
        
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return []

def extract_keywords(articles):
    """Azure OpenAI GPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    
    if not articles:
        print("âŒ ë¶„ì„í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    try:
        client = AzureOpenAI(
            api_key=AZURE_OPENAI_API_KEY,
            api_version="2024-02-15-preview",
            azure_endpoint=AZURE_OPENAI_ENDPOINT
        )
        
        # ê¸°ì‚¬ ë‚´ìš© í•©ì¹˜ê¸° (ì²˜ìŒ 50ê°œ ê¸°ì‚¬ë§Œ ì‚¬ìš©)
        articles_text = "\n".join([f"ì œëª©: {article['title']}\në‚´ìš©: {article['content'][:200]}..." 
                                  for article in articles[:50]])
        
        prompt = f"""
ë‹¤ìŒ IT/ê¸°ìˆ  ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•˜ê³  ê°€ì¥ ì¤‘ìš”í•œ í‚¤ì›Œë“œ 10ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ê¸°ì‚¬ ë‚´ìš©:
{articles_text}

ìš”êµ¬ì‚¬í•­:
1. IT/ê¸°ìˆ  ë¶„ì•¼ì—ì„œ í˜„ì¬ ì£¼ëª©ë°›ëŠ” í‚¤ì›Œë“œ ìœ„ì£¼ë¡œ ì„ ì •
2. ë‹¨ìˆœí•œ ì¼ë°˜ ëª…ì‚¬ê°€ ì•„ë‹Œ êµ¬ì²´ì ì´ê³  ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œ
3. í•œêµ­ì–´ë¡œ ì‘ë‹µ
4. ê° í‚¤ì›Œë“œëŠ” ë„ì–´ì“°ê¸° ì—†ì´ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œ êµ¬ì„±
5. ì‘ë‹µ í˜•ì‹: í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3, ... (ì½¤ë§ˆë¡œ êµ¬ë¶„)

í‚¤ì›Œë“œ:
"""
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ IT/ê¸°ìˆ  ë¶„ì•¼ ë‰´ìŠ¤ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0.3
        )
        
        keywords_text = response.choices[0].message.content.strip()
        keywords = [keyword.strip() for keyword in keywords_text.split(',')]
        
        # í‚¤ì›Œë“œ ì •ë¦¬ (ë¹ˆ ë¬¸ìì—´ ì œê±°)
        keywords = [k for k in keywords if k and len(k) > 1]
        
        print(f"âœ… GPT-4oë¡œ {len(keywords)}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
        print(f"ğŸ“ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {', '.join(keywords)}")
        
        return keywords
        
    except Exception as e:
        print(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ í‚¤ì›Œë“œ ë°˜í™˜
        return ["ì¸ê³µì§€ëŠ¥", "AI", "ë°˜ë„ì²´", "í´ë¼ìš°ë“œ", "ë©”íƒ€ë²„ìŠ¤", "5G", "ë¸”ë¡ì²´ì¸", "ìë™í™”", "IoT", "ë¹…ë°ì´í„°"]

def upload_to_azure_search(articles, keywords):
    """Azure AI Searchì— ë‰´ìŠ¤ ê¸°ì‚¬ ì—…ë¡œë“œ"""
    
    try:
        search_client = SearchClient(
            endpoint=AZURE_SEARCH_ENDPOINT,
            index_name=AZURE_SEARCH_INDEX,
            credential=AzureKeyCredential(AZURE_SEARCH_API_KEY)
        )
        
        # ì—…ë¡œë“œí•  ë¬¸ì„œ ì¤€ë¹„
        documents = []
        for i, article in enumerate(articles):
            doc = {
                "id": f"news_{i}_{int(time.time())}",
                "title": article["title"],
                "content": article["content"],
                "date": article["date"],
                "section": article.get("section", "IT/ê¸°ìˆ "),
                "url": article.get("url", "")
            }
            documents.append(doc)
        
        # ë°°ì¹˜ ì—…ë¡œë“œ (50ê°œì”©)
        batch_size = 50
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i+batch_size]
            result = search_client.upload_documents(batch)
            
            success_count = len([r for r in result if r.succeeded])
            print(f"ğŸ“¤ ë°°ì¹˜ {i//batch_size + 1}: {success_count}/{len(batch)}ê°œ ì—…ë¡œë“œ ì„±ê³µ")
        
        print(f"âœ… ì´ {len(documents)}ê°œ ë¬¸ì„œ Azure AI Search ì—…ë¡œë“œ ì™„ë£Œ")
        
        return True
        
    except Exception as e:
        print(f"âŒ Azure AI Search ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        return False

def generate_analysis_report(articles, keywords):
    """ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    
    try:
        client = AzureOpenAI(
            api_key=AZURE_OPENAI_API_KEY,
            api_version="2024-02-15-preview",
            azure_endpoint=AZURE_OPENAI_ENDPOINT
        )
        
        keywords_text = ", ".join(keywords[:10])
        
        prompt = f"""
ë‹¤ìŒ IT/ê¸°ìˆ  ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ê°„ íŠ¸ë Œë“œ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(articles)}ê°œ
ì£¼ìš” í‚¤ì›Œë“œ: {keywords_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ğŸ” ì£¼ê°„ IT/ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„ ë³´ê³ ì„œ

### ğŸ“Š ìˆ˜ì§‘ í˜„í™©
- ì´ ê¸°ì‚¬ ìˆ˜: {len(articles)}ê°œ
- ìˆ˜ì§‘ ê¸°ê°„: 2025-07-12 ~ 2025-07-18
- ì£¼ìš” ì„¹ì…˜: IT/ê¸°ìˆ 

### ğŸ¯ í•µì‹¬ í‚¤ì›Œë“œ
[ìƒìœ„ 10ê°œ í‚¤ì›Œë“œì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…]

### ğŸ“ˆ ì£¼ìš” íŠ¸ë Œë“œ
[í˜„ì¬ IT/ê¸°ìˆ  ë¶„ì•¼ì—ì„œ ì£¼ëª©ë°›ëŠ” 3ê°€ì§€ íŠ¸ë Œë“œ]

### ğŸ’¡ í–¥í›„ ì „ë§
[í–¥í›„ 1-2ì£¼ê°„ ì˜ˆìƒë˜ëŠ” ê¸°ìˆ  íŠ¸ë Œë“œ]

í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ IT/ê¸°ìˆ  ë¶„ì•¼ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        
        report = response.choices[0].message.content.strip()
        
        # ë³´ê³ ì„œ íŒŒì¼ë¡œ ì €ì¥
        with open("weekly_analysis_report.md", "w", encoding="utf-8") as f:
            f.write(report)
            
        print("âœ… ì£¼ê°„ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ (weekly_analysis_report.md)")
        print("=" * 50)
        print(report)
        
        return report
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def main():
    """ë©”ì¸ ë¶„ì„ ì‹¤í–‰"""
    print("ğŸš€ DeepSearch API ê¸°ë°˜ ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘...")
    print("=" * 50)
    
    # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
    print("\n1ï¸âƒ£ ë‰´ìŠ¤ ìˆ˜ì§‘ ë‹¨ê³„")
    articles = collect_news()
    
    if not articles:
        print("âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
        return
    
    # 2. í‚¤ì›Œë“œ ì¶”ì¶œ
    print("\n2ï¸âƒ£ í‚¤ì›Œë“œ ì¶”ì¶œ ë‹¨ê³„")
    keywords = extract_keywords(articles)
    
    # 3. Azure AI Search ì—…ë¡œë“œ
    print("\n3ï¸âƒ£ Azure AI Search ì—…ë¡œë“œ ë‹¨ê³„")
    upload_success = upload_to_azure_search(articles, keywords)
    
    # 4. ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
    print("\n4ï¸âƒ£ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ë‹¨ê³„")
    report = generate_analysis_report(articles, keywords)
    
    # 5. ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 50)
    print("ğŸ‰ ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(articles)}ê°œ")
    print(f"ğŸ” ì¶”ì¶œëœ í‚¤ì›Œë“œ: {len(keywords)}ê°œ")
    print(f"â˜ï¸ Azure ì—…ë¡œë“œ: {'ì„±ê³µ' if upload_success else 'ì‹¤íŒ¨'}")
    print(f"ğŸ“Š ë¶„ì„ ë³´ê³ ì„œ: {'ìƒì„± ì™„ë£Œ' if report else 'ìƒì„± ì‹¤íŒ¨'}")
    
    if keywords:
        print(f"\nğŸ¯ ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(keywords[:5])}")

if __name__ == "__main__":
    main()
