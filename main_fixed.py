import os
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from dotenv import load_dotenv
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
from openai import AzureOpenAI
from collections import Counter
import requests
import time
from datetime import datetime, timedelta
import uvicorn

load_dotenv()

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_INDEX = os.getenv("AZURE_SEARCH_INDEX")
DEEPSEARCH_API_KEY = os.getenv("DEEPSEARCH_API_KEY")

# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = AzureOpenAI(
    api_key=str(AZURE_OPENAI_API_KEY),
    api_version="2024-02-15-preview",
    azure_endpoint=str(AZURE_OPENAI_ENDPOINT)
)

@app.get("/")
async def serve_home():
    """ë©”ì¸ í˜ì´ì§€ ì œê³µ"""
    return FileResponse("index.html")

@app.get("/api/keywords")
async def get_weekly_keywords():
    """ì˜¬ë°”ë¥¸ í”Œë¡œìš°: DeepSearch â†’ Azure AI Search â†’ GPT-4o â†’ Top 5 í‚¤ì›Œë“œ (ê¸°ì—…ëª… ì œì™¸)"""
    
    try:
        print("ğŸš€ ì˜¬ë°”ë¥¸ News GPT v2 ë¶„ì„ ì‹œì‘")
        
        # 1ï¸âƒ£ DeepSearch APIë¡œ IT/ê¸°ìˆ  ë‰´ìŠ¤ ìˆ˜ì§‘
        print("1ï¸âƒ£ DeepSearch APIë¡œ IT/ê¸°ìˆ  ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        articles = await collect_it_news_from_deepsearch()
        
        if not articles:
            return {"error": "ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨", "keywords": []}
        
        # 2ï¸âƒ£ Azure AI Searchì— ì—…ë¡œë“œ
        print(f"2ï¸âƒ£ Azure AI Searchì— {len(articles)}ê°œ ê¸°ì‚¬ ì—…ë¡œë“œ ì¤‘...")
        upload_success = await upload_articles_to_azure_search(articles)
        
        if not upload_success:
            return {"error": "Azure AI Search ì—…ë¡œë“œ ì‹¤íŒ¨", "keywords": []}
        
        # 3ï¸âƒ£ Azure OpenAI GPT-4oë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê¸°ì—…ëª… ì œì™¸)
        print("3ï¸âƒ£ Azure OpenAI GPT-4oë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
        keywords = await extract_keywords_with_gpt4o(articles)
        
        if not keywords:
            return {"error": "í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨", "keywords": []}
        
        # 4ï¸âƒ£ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ ë° Top 5 ì„ ì •
        print("4ï¸âƒ£ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ ë° Top 5 ì„ ì •...")
        top_keywords = analyze_keyword_frequency(keywords)
        
        # Top 5 í‚¤ì›Œë“œ ë°˜í™˜
        result = []
        for i, kw in enumerate(top_keywords[:5], 1):
            result.append({
                "rank": i,
                "keyword": kw['keyword'],
                "count": kw['count'],
                "source": "ITê¸°ìˆ "
            })
        
        return {
            "keywords": result,
            "total_articles": len(articles),
            "analysis_complete": True,
            "flow": "DeepSearch â†’ Azure AI Search â†’ GPT-4o â†’ Top 5"
        }
        
    except Exception as e:
        print(f"âŒ í‚¤ì›Œë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {"error": str(e), "keywords": []}

async def collect_it_news_from_deepsearch():
    """DeepSearch APIë¡œ IT/ê¸°ìˆ  ë‰´ìŠ¤ ìˆ˜ì§‘"""
    
    if not DEEPSEARCH_API_KEY:
        print("âŒ DeepSearch API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        return []
    
    try:
        articles = []
        tech_keywords = [
            "ì¸ê³µì§€ëŠ¥", "AI", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "ë°˜ë„ì²´", "ì¹©", "í”„ë¡œì„¸ì„œ", 
            "í´ë¼ìš°ë“œ", "ë°ì´í„°ì„¼í„°", "ì†Œí”„íŠ¸ì›¨ì–´", "5G", "6G", "ë¸”ë¡ì²´ì¸", 
            "ë©”íƒ€ë²„ìŠ¤", "VR", "AR", "ë¡œë´‡", "ìë™í™”", "IoT", "ë¹…ë°ì´í„°",
            "ì°¨ì„¸ëŒ€", "í˜ì‹ ê¸°ìˆ ", "ë””ì§€í„¸ì „í™˜", "ìŠ¤ë§ˆíŠ¸íŒ©í† ë¦¬", "ì–‘ìì»´í“¨í„°"
        ]
        
        print(f"ğŸ” IT/ê¸°ìˆ  í‚¤ì›Œë“œ {len(tech_keywords)}ê°œë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        
        # ë‚ ì§œ ë²”ìœ„ë¥¼ ë” ë„“ê²Œ (ìµœê·¼ 7ì¼)
        end_date = datetime.now()
        start_date = end_date - timedelta(days=7)
        
        for keyword in tech_keywords:
            try:
                url = "https://api-v2.deepsearch.com/v1/articles"
                params = {
                    "api_key": DEEPSEARCH_API_KEY,
                    "q": keyword,
                    "limit": 20,  # ë” ë§ì€ ê¸°ì‚¬ ìˆ˜ì§‘
                    "start_date": start_date.strftime("%Y-%m-%d"),
                    "end_date": end_date.strftime("%Y-%m-%d"),
                    "sort": "published_at:desc"
                }
                
                response = requests.get(url, params=params)
                response.raise_for_status()
                
                data = response.json()
                for item in data.get("data", []):
                    pub_date = item.get("published_at", "")
                    if "T" in pub_date:
                        article_date = pub_date.split("T")[0]
                    else:
                        article_date = pub_date
                    
                    articles.append({
                        "id": f"news_{len(articles)}_{int(time.time())}",
                        "title": item.get("title", ""),
                        "content": item.get("summary", "") or item.get("content", ""),
                        "date": article_date
                    })
                
                print(f"  âœ… '{keyword}': {len(data.get('data', []))}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
                time.sleep(0.05)  # API ì œí•œ ë°©ì§€
                
            except Exception as e:
                print(f"  âŒ '{keyword}' ì˜¤ë¥˜: {e}")
                continue
        
        # ì¤‘ë³µ ì œê±°
        unique_articles = []
        seen_titles = set()
        for article in articles:
            if article["title"] not in seen_titles:
                seen_titles.add(article["title"])
                unique_articles.append(article)
        
        print(f"âœ… ì´ {len(unique_articles)}ê°œ ê³ ìœ  ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ")
        return unique_articles
        
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return []

async def upload_articles_to_azure_search(articles):
    """Azure AI Searchì— ê¸°ì‚¬ ì—…ë¡œë“œ"""
    
    try:
        search_client = SearchClient(
            endpoint=str(AZURE_SEARCH_ENDPOINT),
            index_name=str(AZURE_SEARCH_INDEX),
            credential=AzureKeyCredential(str(AZURE_SEARCH_API_KEY))
        )
        
        # ë°°ì¹˜ ì—…ë¡œë“œ (50ê°œì”©)
        batch_size = 50
        total_uploaded = 0
        
        for i in range(0, len(articles), batch_size):
            batch = articles[i:i+batch_size]
            result = search_client.upload_documents(batch)
            
            success_count = len([r for r in result if r.succeeded])
            total_uploaded += success_count
            print(f"  ğŸ“¤ ë°°ì¹˜ {i//batch_size + 1}: {success_count}/{len(batch)}ê°œ ì—…ë¡œë“œ ì„±ê³µ")
        
        print(f"âœ… ì´ {total_uploaded}ê°œ ê¸°ì‚¬ Azure AI Search ì—…ë¡œë“œ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ Azure AI Search ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        return False

async def extract_keywords_with_gpt4o(articles):
    """Azure OpenAI GPT-4oë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê¸°ì—…ëª… ì œì™¸)"""
    
    try:
        # ê¸°ì‚¬ ë‚´ìš© í•©ì¹˜ê¸° (ìµœëŒ€ 100ê°œ ê¸°ì‚¬)
        articles_text = "\n".join([
            f"ì œëª©: {article['title']}\në‚´ìš©: {article['content'][:300]}..."
            for article in articles[:100]
        ])
        
        prompt = f"""
ë‹¤ìŒ IT/ê¸°ìˆ  ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•˜ê³  ê°€ì¥ ì¤‘ìš”í•œ **ê¸°ìˆ  í‚¤ì›Œë“œ**ë§Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ê¸°ì‚¬ ë‚´ìš©:
{articles_text}

âš ï¸ ì¤‘ìš”í•œ ìš”êµ¬ì‚¬í•­:
1. **ê¸°ì—…ëª…/íšŒì‚¬ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”** (ì‚¼ì„±, ì• í”Œ, êµ¬ê¸€, ë„¤ì´ë²„, ì¹´ì¹´ì˜¤, SK, LG, í˜„ëŒ€ ë“± ëª¨ë“  ê¸°ì—…ëª… ì œì™¸)
2. **ê¸°ìˆ  ë¶„ì•¼ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ì„¸ìš”** (ì˜ˆ: ì¸ê³µì§€ëŠ¥, ë°˜ë„ì²´, í´ë¼ìš°ë“œ, 5G, ë¸”ë¡ì²´ì¸ ë“±)
3. êµ¬ì²´ì ì´ê³  ì˜ë¯¸ìˆëŠ” ê¸°ìˆ  ìš©ì–´ ìœ„ì£¼ë¡œ ì„ ì •
4. ê° í‚¤ì›Œë“œì˜ ì˜ˆìƒ ë¹ˆë„ë„ í•¨ê»˜ ì œê³µ (1-50 ë²”ìœ„)
5. í•œêµ­ì–´ë¡œ ì‘ë‹µ
6. **ì‘ë‹µ í˜•ì‹**: í‚¤ì›Œë“œ1:ë¹ˆë„1, í‚¤ì›Œë“œ2:ë¹ˆë„2, ... (ì½¤ë§ˆë¡œ êµ¬ë¶„)

ê¸°ìˆ  í‚¤ì›Œë“œ:
"""
        
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ IT/ê¸°ìˆ  ë‰´ìŠ¤ ì „ë¬¸ í‚¤ì›Œë“œ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê¸°ì—…ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•Šê³  ê¸°ìˆ  ìš©ì–´ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.2
        )
        
        keywords_text = response.choices[0].message.content or ""
        print(f"GPT-4o ì‘ë‹µ: {keywords_text}")
        
        # í‚¤ì›Œë“œ:ë¹ˆë„ íŒŒì‹±
        keywords = []
        for item in keywords_text.split(','):
            if ':' in item:
                parts = item.strip().split(':', 1)
                keyword = parts[0].strip()
                try:
                    count = int(parts[1].strip())
                    # ê¸°ì—…ëª… í•„í„°ë§ (ì¶”ê°€ ë³´ì•ˆ)
                    company_names = ['ì‚¼ì„±', 'ì• í”Œ', 'êµ¬ê¸€', 'ë„¤ì´ë²„', 'ì¹´ì¹´ì˜¤', 'SK', 'LG', 'í˜„ëŒ€', 
                                   'TSMC', 'ì—”ë¹„ë””ì•„', 'ì¸í…”', 'í€„ì»´', 'AMD', 'Microsoft', 'IBM']
                    if not any(company in keyword for company in company_names):
                        keywords.append({"keyword": keyword, "count": count})
                except:
                    if not any(company in keyword for company in company_names):
                        keywords.append({"keyword": keyword, "count": 15})
        
        print(f"âœ… GPT-4oë¡œ {len(keywords)}ê°œ ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
        return keywords
        
    except Exception as e:
        print(f"âŒ GPT-4o í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return []

def analyze_keyword_frequency(keywords):
    """í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ ë° ì •ë ¬"""
    
    if not keywords:
        return []
    
    # ë¹ˆë„ ê¸°ì¤€ ì •ë ¬
    sorted_keywords = sorted(keywords, key=lambda x: x['count'], reverse=True)
    
    return sorted_keywords

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8010, reload=True)
