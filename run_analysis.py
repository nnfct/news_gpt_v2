import os
from dotenv import load_dotenv
import json
import urllib.parse
from collections import Counter
import time

load_dotenv()

import requests
import openai
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
import pandas as pd

AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_INDEX = os.getenv("AZURE_SEARCH_INDEX")
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

def collect_news():
    """ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¡œ IT/ê¸°ìˆ  ë¶„ì•¼ 7ì¼ì¹˜ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET or NAVER_CLIENT_ID == "your_naver_client_id":
        print("âš ï¸ Naver API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return [
            {"title": "AI ê¸°ìˆ  ë°œì „ìœ¼ë¡œ ë¯¸ë˜ ì¼ìë¦¬ ë³€í™” ì˜ˆìƒ", "content": "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ê¸‰ì†í•œ ë°œì „ìœ¼ë¡œ ì¸í•´ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ ì¼ìë¦¬ êµ¬ì¡°ì˜ ë³€í™”ê°€ ì˜ˆìƒëœë‹¤ê³  ì „ë¬¸ê°€ë“¤ì´ ë¶„ì„í–ˆë‹¤.", "section": "IT/ê¸°ìˆ ", "url": "https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=001&aid=0014567890", "date": "2025-07-18"},
            {"title": "ë°˜ë„ì²´ ì‚°ì—… ì„±ì¥ê³¼ ê¸€ë¡œë²Œ ê²½ìŸë ¥", "content": "êµ­ë‚´ ë°˜ë„ì²´ ê¸°ì—…ë“¤ì´ ì°¨ì„¸ëŒ€ ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ê°œë°œì— ë°•ì°¨ë¥¼ ê°€í•˜ë©° ê¸€ë¡œë²Œ ì‹œì¥ì—ì„œì˜ ê²½ìŸë ¥ì„ ê°•í™”í•˜ê³  ìˆë‹¤.", "section": "IT/ê¸°ìˆ ", "url": "https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=001&aid=0014567891", "date": "2025-07-17"},
            {"title": "í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì‹œì¥ í™•ëŒ€", "content": "ì½”ë¡œë‚˜19 ì´í›„ ë””ì§€í„¸ ì „í™˜ì´ ê°€ì†í™”ë˜ë©´ì„œ í´ë¼ìš°ë“œ ì»´í“¨íŒ… ì„œë¹„ìŠ¤ ì‹œì¥ì´ ê¸‰ì†íˆ ì„±ì¥í•˜ê³  ìˆë‹¤.", "section": "IT/ê¸°ìˆ ", "url": "https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=001&aid=0014567892", "date": "2025-07-16"}
        ]
    
    try:
        news_list = []
        
        # IT/ê¸°ìˆ  ë¶„ì•¼ ì „ë¬¸ í‚¤ì›Œë“œë“¤
        tech_keywords = [
            "ì¸ê³µì§€ëŠ¥", "AI", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹",
            "ë°˜ë„ì²´", "ì¹©", "í”„ë¡œì„¸ì„œ", "ë©”ëª¨ë¦¬",
            "í´ë¼ìš°ë“œ", "ë°ì´í„°ì„¼í„°", "ì„œë²„",
            "ì†Œí”„íŠ¸ì›¨ì–´", "ì•±", "í”Œë«í¼",
            "5G", "6G", "í†µì‹ ", "ë„¤íŠ¸ì›Œí¬",
            "ë¸”ë¡ì²´ì¸", "ì•”í˜¸í™”í", "ë¹„íŠ¸ì½”ì¸",
            "ë©”íƒ€ë²„ìŠ¤", "VR", "AR", "ê°€ìƒí˜„ì‹¤",
            "ë¡œë´‡", "ìë™í™”", "IoT", "ìŠ¤ë§ˆíŠ¸í™ˆ"
        ]
        
        headers = {
            "X-Naver-Client-Id": NAVER_CLIENT_ID,
            "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
        }
        
        print(f"ğŸ” IT/ê¸°ìˆ  ë¶„ì•¼ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ({len(tech_keywords)}ê°œ í‚¤ì›Œë“œ ì‚¬ìš©)...")
        
        # ê° í‚¤ì›Œë“œë³„ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘
        for keyword in tech_keywords:
            encoded_query = urllib.parse.quote(keyword)
            # displayë¥¼ 10ìœ¼ë¡œ ëŠ˜ë ¤ì„œ ë” ë§ì€ ë‰´ìŠ¤ ìˆ˜ì§‘
            url = f"https://openapi.naver.com/v1/search/news.json?query={encoded_query}&display=10&start=1&sort=date"
            
            try:
                response = requests.get(url, headers=headers)
                response.raise_for_status()
                
                data = response.json()
                items = data.get("items", [])
                
                for item in items:
                    # HTML íƒœê·¸ ì œê±°
                    title = item.get("title", "").replace("<b>", "").replace("</b>", "").replace("&quot;", '"')
                    description = item.get("description", "").replace("<b>", "").replace("</b>", "").replace("&quot;", '"')
                    link = item.get("link", "")  # ê¸°ì‚¬ ì›ë¬¸ URL ì¶”ê°€
                    pub_date = item.get("pubDate", "")  # ë„¤ì´ë²„ APIì—ì„œ ì œê³µí•˜ëŠ” ë°œí–‰ì¼
                    
                    # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (RFC2822 -> YYYY-MM-DD)
                    formatted_date = ""
                    if pub_date:
                        try:
                            from datetime import datetime
                            # ë„¤ì´ë²„ API pubDateëŠ” "Mon, 17 Jul 2025 14:30:00 +0900" í˜•ì‹
                            dt = datetime.strptime(pub_date, "%a, %d %b %Y %H:%M:%S %z")
                            formatted_date = dt.strftime("%Y-%m-%d")
                        except:
                            formatted_date = "2025-07-17"  # ê¸°ë³¸ê°’
                    else:
                        formatted_date = "2025-07-17"  # ê¸°ë³¸ê°’
                    
                    # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ì²´í¬
                    is_duplicate = False
                    for existing_news in news_list:
                        if existing_news["title"] == title:
                            is_duplicate = True
                            break
                    
                    if not is_duplicate:
                        news_list.append({
                            "title": title,
                            "content": description,
                            "section": "IT/ê¸°ìˆ ",
                            "keyword": keyword,
                            "date": formatted_date
                        })
                    
                print(f"  âœ… '{keyword}' í‚¤ì›Œë“œë¡œ {len(items)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±° í›„ ì¶”ê°€)")
                
                # API ìš”ì²­ ì œí•œì„ í”¼í•˜ê¸° ìœ„í•œ ë”œë ˆì´
                time.sleep(0.1)
                
            except Exception as e:
                print(f"  âŒ '{keyword}' í‚¤ì›Œë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                time.sleep(1)  # ì—ëŸ¬ ë°œìƒ ì‹œ ë” ê¸´ ë”œë ˆì´
                continue
        
        print(f"\nâœ… ì´ {len(news_list)}ê°œ IT/ê¸°ìˆ  ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return news_list
        
    except Exception as e:
        print(f"âŒ ë„¤ì´ë²„ API ì˜¤ë¥˜: {e}")
        print("âš ï¸ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return [
            {"title": "AI ê¸°ìˆ  ë°œì „ìœ¼ë¡œ ë¯¸ë˜ ì¼ìë¦¬ ë³€í™” ì˜ˆìƒ", "content": "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ê¸‰ì†í•œ ë°œì „ìœ¼ë¡œ ì¸í•´ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ ì¼ìë¦¬ êµ¬ì¡°ì˜ ë³€í™”ê°€ ì˜ˆìƒëœë‹¤ê³  ì „ë¬¸ê°€ë“¤ì´ ë¶„ì„í–ˆë‹¤.", "section": "IT/ê¸°ìˆ ", "date": "2025-07-18"},
            {"title": "ë°˜ë„ì²´ ì‚°ì—… ì„±ì¥ê³¼ ê¸€ë¡œë²Œ ê²½ìŸë ¥", "content": "êµ­ë‚´ ë°˜ë„ì²´ ê¸°ì—…ë“¤ì´ ì°¨ì„¸ëŒ€ ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ê°œë°œì— ë°•ì°¨ë¥¼ ê°€í•˜ë©° ê¸€ë¡œë²Œ ì‹œì¥ì—ì„œì˜ ê²½ìŸë ¥ì„ ê°•í™”í•˜ê³  ìˆë‹¤.", "section": "IT/ê¸°ìˆ ", "date": "2025-07-17"}
        ]

def extract_keywords(news):
    # Azure OpenAI GPT-4oë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ (Top 3ë§Œ)
    openai.api_type = "azure"
    openai.api_key = AZURE_OPENAI_API_KEY
    openai.azure_endpoint = AZURE_OPENAI_ENDPOINT
    openai.api_version = "2024-02-15-preview"
    prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ í‚¤ì›Œë“œ 3ê°œë§Œ ì½¤ë§ˆë¡œ êµ¬ë¶„í•´ ì¶”ì¶œí•´ì¤˜. ìˆœì„œëŠ” ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ.\në‰´ìŠ¤: {news['content']}"
    try:
        completion = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‰´ìŠ¤ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í‚¤ì›Œë“œ 3ê°œë§Œ ì¶”ì¶œí•˜ëŠ” ë´‡ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )
        keywords_str = completion.choices[0].message.content
        if not keywords_str:
            return []
        keywords = [k.strip() for k in str(keywords_str).split(",") if k.strip()]
        # Top 3ë§Œ ë°˜í™˜
        return keywords[:3]
    except Exception as e:
        print(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return []

# def generate_cardnews(keywords):
#     # Azure OpenAI GPT-4oë¡œ ì¹´ë“œë‰´ìŠ¤ ìƒì„± (í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
#     openai.api_type = "azure"
#     openai.api_key = AZURE_OPENAI_API_KEY
#     openai.azure_endpoint = AZURE_OPENAI_ENDPOINT
#     openai.api_version = "2024-02-15-preview"
#     prompt = f"ë‹¤ìŒ í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ë¶„ì„ ì¹´ë“œë‰´ìŠ¤ìš© ìš”ì•½ í…ìŠ¤íŠ¸(3~4ë¬¸ì¥, 300ì ë‚´ì™¸, ì‰½ê³  ëª…í™•í•˜ê²Œ)ë¥¼ ìƒì„±í•´ì¤˜.\ní‚¤ì›Œë“œ: {', '.join(keywords)}"
#     try:
#         completion = openai.chat.completions.create(
#             model="gpt-4o",
#             messages=[
#                 {"role": "system", "content": "ì¹´ë“œë‰´ìŠ¤ìš© ìš”ì•½ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë´‡ì…ë‹ˆë‹¤."},
#                 {"role": "user", "content": prompt}
#             ]
#         )
#         content = completion.choices[0].message.content
#         if not content:
#             return ""
#         return str(content).strip()
#     except Exception as e:
#         print(f"ì¹´ë“œë‰´ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
#         return ""

def get_embedding(text):
    # Azure OpenAI text-embedding-ada-002ë¡œ ì„ë² ë”© ìƒì„±
    openai.api_type = "azure"
    openai.api_key = AZURE_OPENAI_API_KEY
    openai.azure_endpoint = AZURE_OPENAI_ENDPOINT
    openai.api_version = "2024-02-15-preview"
    try:
        response = openai.embeddings.create(
            input=text,
            model="text-embedding-ada-002"
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
        return [0.0] * 1536

def analyze_weekly_keywords(news_list):
    """7ì¼ì¹˜ ë‰´ìŠ¤ì—ì„œ ì „ì²´ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„í•˜ì—¬ Top 3 ì¶”ì¶œ"""
    print(f"\nğŸ” {len(news_list)}ê°œ ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ ì¤‘...")
    
    all_keywords = []
    
    # ê° ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    for idx, news in enumerate(news_list):
        print(f"  ğŸ“„ {idx+1}/{len(news_list)} ì²˜ë¦¬ ì¤‘...")
        keywords = extract_keywords(news)
        all_keywords.extend(keywords)
    
    # í‚¤ì›Œë“œ ë¹ˆë„ ê³„ì‚°
    keyword_counter = Counter(all_keywords)
    print(f"\nğŸ“Š ì´ {len(all_keywords)}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ, ê³ ìœ  í‚¤ì›Œë“œ {len(keyword_counter)}ê°œ")
    
    # Top 3 í‚¤ì›Œë“œ ì„ ì •
    top_3_keywords = [keyword for keyword, count in keyword_counter.most_common(3)]
    
    print(f"\nğŸ† 1ì£¼ì°¨ Top 3 í‚¤ì›Œë“œ:")
    for i, (keyword, count) in enumerate(keyword_counter.most_common(3), 1):
        print(f"  {i}. [{keyword}] - {count}íšŒ ì–¸ê¸‰")
    
    return top_3_keywords, keyword_counter

def upload_news_articles(news_list):
    """ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ Azure Searchì— ì—…ë¡œë“œ"""
    try:
        endpoint = AZURE_SEARCH_ENDPOINT or ""
        index_name = AZURE_SEARCH_INDEX or ""
        api_key = AZURE_SEARCH_API_KEY or ""
        client = SearchClient(
            endpoint=str(endpoint),
            index_name=str(index_name),
            credential=AzureKeyCredential(str(api_key))
        )
        
        print(f"ğŸ“¤ {len(news_list)}ê°œ ë‰´ìŠ¤ ê¸°ì‚¬ ì—…ë¡œë“œ ì¤‘...")
        
        # ê¸°ì‚¬ ë¬¸ì„œ ìƒì„±
        documents = []
        for i, news in enumerate(news_list):
            doc = {
                "id": f"news_article_{i+1}_{hash(news['title']) % 1000000:06d}",
                "title": news.get("title", ""),
                "content": news.get("content", ""),
                "date": news.get("date", "2025-07-17"),
                "section": news.get("section", "IT/ê¸°ìˆ "),
                "keyword": news.get("keyword", "")
            }
            documents.append(doc)
        
        # ë°°ì¹˜ ì—…ë¡œë“œ (í•œ ë²ˆì— ìµœëŒ€ 1000ê°œ)
        batch_size = 50
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i+batch_size]
            result = client.upload_documents(documents=batch)
            
            success_count = sum(1 for r in result if r.succeeded)
            print(f"  âœ… ë°°ì¹˜ {i//batch_size + 1}: {success_count}/{len(batch)}ê°œ ì„±ê³µ")
            
        print(f"âœ… ì´ {len(documents)}ê°œ ë‰´ìŠ¤ ê¸°ì‚¬ ì—…ë¡œë“œ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ ê¸°ì‚¬ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")

def upload_weekly_summary(top_3_keywords, keyword_counter):
    """ì£¼ê°„ í‚¤ì›Œë“œ ìš”ì•½ì„ Azure Searchì— ì—…ë¡œë“œ"""
    try:
        endpoint = AZURE_SEARCH_ENDPOINT or ""
        index_name = AZURE_SEARCH_INDEX or ""
        api_key = AZURE_SEARCH_API_KEY or ""
        client = SearchClient(
            endpoint=str(endpoint),
            index_name=str(index_name),
            credential=AzureKeyCredential(str(api_key))
        )
        
        # ì£¼ê°„ ìš”ì•½ ë¬¸ì„œ ìƒì„±
        weekly_summary = f"2025ë…„ 7ì›” 3ì£¼ì°¨ Top 3 í‚¤ì›Œë“œ: [{top_3_keywords[0]}] [{top_3_keywords[1]}] [{top_3_keywords[2]}]"
        
        # ìƒì„¸ í†µê³„ ì¶”ê°€
        detailed_stats = []
        for keyword, count in keyword_counter.most_common(10):  # Top 10ê¹Œì§€
            detailed_stats.append(f"{keyword}({count}íšŒ)")
        
        content = f"{weekly_summary}\n\nìƒì„¸ í†µê³„: " + ", ".join(detailed_stats)
        
        doc = {
            "id": "weekly_summary_2025_week3",  # ì£¼ì°¨ë³„ ê³ ìœ  ID
            "title": "2025ë…„ 7ì›” 3ì£¼ì°¨ IT/ê¸°ìˆ  ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„",
            "content": content,
            "date": "2025-07-17"
        }
        
        result = client.upload_documents(documents=[doc])
        if not result[0].succeeded:
            print(f"âŒ ì£¼ê°„ ìš”ì•½ ì—…ë¡œë“œ ì‹¤íŒ¨: {result[0].error_message}")
        else:
            print(f"âœ… ì£¼ê°„ ìš”ì•½ ì—…ë¡œë“œ ì„±ê³µ!")
            print(f"ğŸ“„ ì—…ë¡œë“œëœ ë‚´ìš©: {content[:100]}...")
            
    except Exception as e:
        print(f"âŒ ì£¼ê°„ ìš”ì•½ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    print("ğŸ“° 7ì¼ì¹˜ ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰")
    
    # 1ë‹¨ê³„: 7ì¼ì¹˜ ë‰´ìŠ¤ ìˆ˜ì§‘
    news_list = collect_news()
    
    # 2ë‹¨ê³„: ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ Azure Searchì— ì—…ë¡œë“œ
    upload_news_articles(news_list)
    
    # 3ë‹¨ê³„: ì „ì²´ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
    top_3_keywords, keyword_counter = analyze_weekly_keywords(news_list)
    
    # 4ë‹¨ê³„: ì£¼ê°„ ìš”ì•½ ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ¯ ìµœì¢… ê²°ê³¼:")
    print(f"2025ë…„ 7ì›” 3ì£¼ì°¨ Top 3 í‚¤ì›Œë“œ: [{top_3_keywords[0]}] [{top_3_keywords[1]}] [{top_3_keywords[2]}]")
    
    # 5ë‹¨ê³„: Azure Searchì— ì£¼ê°„ ìš”ì•½ ì—…ë¡œë“œ
    upload_weekly_summary(top_3_keywords, keyword_counter)
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ì›¹í˜ì´ì§€ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
