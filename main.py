# ëª¨ë“  í•„ìš”í•œ import ë¬¸ë“¤ì„ íŒŒì¼ ìƒë‹¨ì— ì •ë¦¬
import os
import re
import time
import logging
import requests
from fastapi import FastAPI, HTTPException, Query, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from dotenv import load_dotenv
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
from openai import AzureOpenAI
import uvicorn
from functools import wraps

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
logger = logging.getLogger("news_gpt_v2")

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# FastAPI ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_INDEX = os.getenv("AZURE_SEARCH_INDEX")
DEEPSEARCH_API_KEY = os.getenv("DEEPSEARCH_API_KEY")

# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = AzureOpenAI(
    api_key=str(AZURE_OPENAI_API_KEY),
    api_version="2024-02-15-preview",
    azure_endpoint=str(AZURE_OPENAI_ENDPOINT)
)

# API í˜¸ì¶œ ì¬ì‹œë„ ë°ì½”ë ˆì´í„°
def retry_on_exception(max_retries=3, delay=0.5, backoff=2, allowed_exceptions=(Exception,)):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            retries = 0
            current_delay = delay
            while True:
                try:
                    return func(*args, **kwargs)
                except allowed_exceptions as e:
                    retries += 1
                    logger.warning(f"{func.__name__} ì‹¤íŒ¨({retries}/{max_retries}): {e}")
                    if retries >= max_retries:
                        logger.error(f"{func.__name__} ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼: {e}")
                        raise
                    time.sleep(current_delay)
                    current_delay *= backoff
        return wrapper
    return decorator

# =============================================================================
# API ì—”ë“œí¬ì¸íŠ¸ë“¤
# =============================================================================

@app.get("/")
async def serve_home():
    """ë©”ì¸ í˜ì´ì§€ ì œê³µ"""
    return FileResponse("index.html")

@app.get("/keyword-articles")
async def get_keyword_articles(
    keyword: str = Query(..., description="ê²€ìƒ‰í•  í‚¤ì›Œë“œ"),
    start_date: str = Query(..., description="ì‹œì‘ì¼ (YYYY-MM-DD)"),
    end_date: str = Query(..., description="ì¢…ë£Œì¼ (YYYY-MM-DD)")
):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ê´€ë ¨ ê¸°ì‚¬ ê²€ìƒ‰ API"""
    try:
        articles = await search_keyword_articles(keyword, start_date, end_date)
        return {
            "keyword": keyword,
            "total": len(articles),
            "articles": articles,
            "period": f"{start_date} ~ {end_date}",
            "status": "success"
        }
    except Exception as e:
        logger.error(f"/keyword-articles ì˜¤ë¥˜: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={
            "error": str(e),
            "keyword": keyword,
            "articles": [],
            "total": 0
        })

# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =============================================================================
# í‚¤ì›Œë“œ ê¸°ë°˜ ê¸°ì‚¬ ê²€ìƒ‰ í•¨ìˆ˜
async def search_keyword_articles(keyword: str, start_date: str = "2025-07-14", end_date: str = "2025-07-18"):
    """íŠ¹ì • í‚¤ì›Œë“œë¡œ ê¸°ì‚¬ ê²€ìƒ‰ (ë” ì •í™•í•œ ê²€ìƒ‰, í•œêµ­ì–´ ìš°ì„ , ë‚ ì§œ í•„í„°ë§)"""
    if not DEEPSEARCH_API_KEY:
        logger.error("âŒ DeepSearch API í‚¤ ì—†ìŒ")
        return []
    try:
        # IT í‚¤ì›Œë“œì— ëŒ€í•´ì„œë§Œ ì •í™•í•œ ê²€ìƒ‰
        if keyword == "IT":
            search_terms = ["IT", "ì •ë³´ê¸°ìˆ ", "Information Technology"]
        else:
            search_terms = [keyword]
        articles = []
        for search_term in search_terms:
            try:
                url = "https://api-v2.deepsearch.com/v1/articles"
                params = {
                    "api_key": DEEPSEARCH_API_KEY,
                    "q": search_term,
                    "limit": 20,
                    "start_date": start_date,
                    "end_date": end_date,
                    "sort": "published_at:desc"
                }
                response = requests.get(url, params=params, timeout=15)
                response.raise_for_status()
                data = response.json()
                for item in data.get("data", []):
                    pub_date = item.get("published_at", "")
                    if "T" in pub_date:
                        article_date = pub_date.split("T")[0]
                    else:
                        article_date = pub_date
                    if article_date:
                        title = item.get("title", "")
                        content = item.get("summary", "") or item.get("content", "")
                        # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°(ê°„ë‹¨í™”)
                        relevance_score = 1.0 if keyword in title or keyword in content else 0.5
                        korean_chars = len([c for c in title + content if ord(c) >= 0xAC00 and ord(c) <= 0xD7A3])
                        total_chars = len(title + content)
                        is_korean = korean_chars / max(total_chars, 1) > 0.3
                        articles.append({
                            "title": title,
                            "content": content,
                            "source_url": item.get("content_url", "") or item.get("url", ""),
                            "date": article_date,
                            "relevance_score": relevance_score,
                            "search_term": search_term,
                            "is_korean": is_korean
                        })
            except Exception as e:
                logger.warning(f"âŒ '{search_term}' ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                continue
        # ì¤‘ë³µ ì œê±° (ì œëª© ê¸°ì¤€)
        unique_articles = []
        seen_titles = set()
        for article in articles:
            title = article.get("title", "")
            if title and title not in seen_titles:
                seen_titles.add(title)
                unique_articles.append(article)
        # í•œêµ­ì–´ ê¸°ì‚¬ ìš°ì„  + ê´€ë ¨ì„± ì ìˆ˜ ê¸°ë°˜ ì •ë ¬
        unique_articles.sort(key=lambda x: (
            not x.get("is_korean", False),
            -x.get("relevance_score", 0),
            x.get("date", "")
        ))
        logger.info(f"âœ… '{keyword}' ({start_date}~{end_date}): {len(unique_articles)}ê°œ ê´€ë ¨ ê¸°ì‚¬ ê²€ìƒ‰ ì™„ë£Œ (í•œêµ­ì–´ ìš°ì„ , ê´€ë ¨ì„± í•„í„°ë§)")
        return unique_articles[:12]
    except Exception as e:
        logger.error(f"âŒ '{keyword}' ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

@app.get("/api/articles")
async def get_articles(start_date: str = "2025-07-14", end_date: str = "2025-07-18", limit: int = 10):
    """ê¸°ì‚¬ ìš”ì•½ë³¸ ë°˜í™˜ API"""
    try:
        logger.info(f"ğŸ“° ê¸°ì‚¬ ìš”ì•½ë³¸ ìš”ì²­ - ê¸°ê°„: {start_date} ~ {end_date}, ê°œìˆ˜: {limit}")
        articles = await collect_it_news_from_deepsearch(start_date, end_date)
        if not articles:
            logger.warning("ê¸°ì‚¬ ì—†ìŒ: DeepSearch API ê²°ê³¼ ì—†ìŒ")
            return JSONResponse(status_code=200, content={"articles": [], "message": "ê¸°ì‚¬ ì—†ìŒ", "total": 0})
        summarized_articles = []
        for article in articles[:limit]:
            content = article.get("content", "")
            summary = content[:200] + "..." if len(content) > 200 else content
            summarized_articles.append({
                "id": article.get("id", ""),
                "title": article.get("title", ""),
                "summary": summary,
                "date": article.get("date", ""),
                "source_url": article.get("source_url", ""),
                "keyword": article.get("keyword", "")
            })
        return {
            "articles": summarized_articles,
            "total": len(articles),
            "period": f"{start_date} ~ {end_date}",
            "status": "success"
        }
    except Exception as e:
        logger.error(f"/api/articles ì˜¤ë¥˜: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"error": str(e), "articles": [], "total": 0})


# /api/keywords ì—”ë“œí¬ì¸íŠ¸(ìµœì‹ /ì •ë¦¬ë³¸)
@app.get("/api/keywords")
async def get_weekly_keywords(start_date: str = "2025-07-14", end_date: str = "2025-07-18"):
    """DeepSearch â†’ Azure AI Search â†’ GPT-4o â†’ Top 5 í‚¤ì›Œë“œ ë°˜í™˜"""
    try:
        logger.info(f"ğŸš€ News GPT v2 ë¶„ì„ ì‹œì‘ - ê¸°ê°„: {start_date} ~ {end_date}")
        if not all([AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, DEEPSEARCH_API_KEY]):
            logger.error("í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜¤ë¥˜: Azure OpenAI ë˜ëŠ” DeepSearch API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return {
                "error": "í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜¤ë¥˜", 
                "keywords": [],
                "details": "Azure OpenAI ë˜ëŠ” DeepSearch API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }
        articles = await collect_it_news_from_deepsearch(start_date, end_date)
        if not articles:
            logger.warning("/api/keywords: ê¸°ì‚¬ ì—†ìŒ")
            return {
                "error": "ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨", 
                "keywords": [],
                "details": "DeepSearch APIì—ì„œ ê¸°ì‚¬ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
        logger.info(f"   âœ… {len(articles)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ")
        upload_success = await upload_articles_to_azure_search(articles)
        if not upload_success:
            logger.warning("   âš ï¸ Azure AI Search ì—…ë¡œë“œ ì‹¤íŒ¨, ê³„ì† ì§„í–‰")
        logger.info("3ï¸âƒ£ Azure OpenAI GPT-4oë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
        keywords = await extract_keywords_with_gpt4o(articles)
        if not keywords:
            logger.warning("/api/keywords: í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©")
            keywords = [
                {"keyword": "ì¸ê³µì§€ëŠ¥", "count": 25},
                {"keyword": "ë°˜ë„ì²´", "count": 20},
                {"keyword": "í´ë¼ìš°ë“œ", "count": 18},
                {"keyword": "ë©”íƒ€ë²„ìŠ¤", "count": 15},
                {"keyword": "ë¸”ë¡ì²´ì¸", "count": 12}
            ]
        logger.info(f"   âœ… {len(keywords)}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
        result = []
        for i, kw in enumerate(keywords[:5], 1):
            result.append({
                "rank": i,
                "keyword": kw['keyword'],
                "count": kw['count'],
                "source": "ITê¸°ìˆ "
            })
        return {
            "keywords": result,
            "total_articles": len(articles),
            "date_range": f"{start_date} ~ {end_date}",
            "flow": "DeepSearch â†’ Azure AI Search â†’ GPT-4o",
            "status": "ì„±ê³µ"
        }
    except Exception as e:
        logger.error(f"/api/keywords ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {e}", exc_info=True)
        return {
            "error": "ì‹œìŠ¤í…œ ì˜¤ë¥˜",
            "keywords": [],
            "details": str(e),
            "fallback_keywords": [
                {"rank": 1, "keyword": "ì¸ê³µì§€ëŠ¥", "count": 25, "source": "ITê¸°ìˆ "},
                {"rank": 2, "keyword": "ë°˜ë„ì²´", "count": 20, "source": "ITê¸°ìˆ "},
                {"rank": 3, "keyword": "í´ë¼ìš°ë“œ", "count": 18, "source": "ITê¸°ìˆ "},
                {"rank": 4, "keyword": "ë©”íƒ€ë²„ìŠ¤", "count": 15, "source": "ITê¸°ìˆ "},
                {"rank": 5, "keyword": "ë¸”ë¡ì²´ì¸", "count": 12, "source": "ITê¸°ìˆ "}
            ]
        }




# API í˜¸ì¶œì— ì¬ì‹œë„ ì ìš©
@retry_on_exception(max_retries=3, delay=0.5, backoff=2, allowed_exceptions=(requests.RequestException,))
def deepsearch_api_request(url, params):
    """DeepSearch API ìš”ì²­ (ì¬ì‹œë„/ë¡œê¹… ì¼ê´€ì„±)"""
    logger.info(f"DeepSearch API ìš”ì²­: {url} | params: {params}")
    response = requests.get(url, params=params, timeout=10)
    logger.info(f"DeepSearch ì‘ë‹µ ì½”ë“œ: {response.status_code}")
    response.raise_for_status()
    return response.json()

async def collect_it_news_from_deepsearch(start_date: str, end_date: str):
    """DeepSearch APIë¡œ IT/ê¸°ìˆ  ë‰´ìŠ¤ ìˆ˜ì§‘ (ë¡œê¹…/ì¤‘ë³µì œê±°/ìƒ˜í”Œ fallback)"""
    if not DEEPSEARCH_API_KEY:
        logger.error("âŒ DeepSearch API í‚¤ ì—†ìŒ")
        return []
    try:
        articles = []
        tech_keywords = ["IT", "ê¸°ìˆ ", "ì¸ê³µì§€ëŠ¥", "AI", "ë°˜ë„ì²´"]
        logger.info(f"ğŸ” DeepSearch APIë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... ({start_date} ~ {end_date})")
        for keyword in tech_keywords:
            try:
                url = "https://api-v2.deepsearch.com/v1/articles"
                params = {
                    "api_key": DEEPSEARCH_API_KEY,
                    "q": keyword,
                    "limit": 15,
                    "start_date": start_date,
                    "end_date": end_date,
                    "sort": "published_at:desc"
                }
                data = deepsearch_api_request(url, params)
                # ì‘ë‹µ êµ¬ì¡° í™•ì¸
                if "data" in data:
                    articles_data = data["data"]
                elif "articles" in data:
                    articles_data = data["articles"]
                else:
                    logger.warning(f"    âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì‘ë‹µ êµ¬ì¡°: {list(data.keys())}")
                    continue
                for item in articles_data:
                    pub_date = item.get("published_at", "")
                    if "T" in pub_date:
                        article_date = pub_date.split("T")[0]
                    else:
                        article_date = pub_date
                    title = item.get("title", "").strip()
                    content = (item.get("summary", "") or item.get("content", "")).strip()
                    if title and content:
                        articles.append({
                            "id": f"news_{keyword}_{hash(title)%100000}",
                            "title": title,
                            "content": content,
                            "date": article_date,
                            "source_url": item.get("content_url", "") or item.get("url", ""),
                            "keyword": keyword
                        })
                logger.info(f"    âœ… '{keyword}': {len(articles_data)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
                time.sleep(0.2)
            except Exception as e:
                logger.warning(f"    âŒ '{keyword}' ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
        # ì¤‘ë³µ ì œê±° (ì œëª©+ë‚´ìš© í•´ì‹œ)
        unique_articles = []
        seen_hashes = set()
        for article in articles:
            hash_key = hash((article["title"].lower(), article["content"][:100].lower()))
            if hash_key not in seen_hashes:
                seen_hashes.add(hash_key)
                unique_articles.append(article)
        logger.info(f"âœ… ì´ {len(unique_articles)}ê°œ ê³ ìœ  ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ")
        return unique_articles[:30]
    except Exception as e:
        logger.error(f"âŒ DeepSearch API ì „ì²´ ì˜¤ë¥˜: {e}", exc_info=True)
        # ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜ (API ì‹¤íŒ¨ ì‹œ)
        return [
            {
                "id": "sample_1",
                "title": "AI ê¸°ìˆ  ë°œì „ìœ¼ë¡œ IT ì—…ê³„ ë³€í™” ê°€ì†í™”",
                "content": "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ê¸‰ì†í•œ ë°œì „ìœ¼ë¡œ IT ì—…ê³„ ì „ë°˜ì— ë³€í™”ê°€ ì¼ì–´ë‚˜ê³  ìˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ ê¸°ìˆ ì„ í™œìš©í•œ ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ë“¤ì´ ë“±ì¥í•˜ê³  ìˆìœ¼ë©°, ê¸°ì—…ë“¤ì€ ë””ì§€í„¸ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ì„ ê°€ì†í™”í•˜ê³  ìˆë‹¤.",
                "date": start_date,
                "source_url": "https://example.com/ai-news",
                "keyword": "AI"
            },
            {
                "id": "sample_2",
                "title": "ë°˜ë„ì²´ ì‚°ì—… íšŒë³µ ì¡°ì§, ê¸€ë¡œë²Œ ê³µê¸‰ë§ ì•ˆì •í™”",
                "content": "ë°˜ë„ì²´ ì‚°ì—…ì´ íšŒë³µ ì¡°ì§ì„ ë³´ì´ë©° ê¸€ë¡œë²Œ ê³µê¸‰ë§ì´ ì•ˆì •í™”ë˜ê³  ìˆë‹¤. ì£¼ìš” ë°˜ë„ì²´ ê¸°ì—…ë“¤ì˜ ì‹¤ì ì´ ê°œì„ ë˜ê³  ìˆìœ¼ë©°, ìƒˆë¡œìš´ ê¸°ìˆ  ê°œë°œì— ëŒ€í•œ íˆ¬ìë„ ì¦ê°€í•˜ê³  ìˆë‹¤.",
                "date": start_date,
                "source_url": "https://example.com/semiconductor-news",
                "keyword": "ë°˜ë„ì²´"
            }
        ]


async def upload_articles_to_azure_search(articles):
    """Azure AI Searchì— ê¸°ì‚¬ ì—…ë¡œë“œ (ë¡œê¹…/ì˜ˆì™¸ì²˜ë¦¬ ì¼ê´€ì„±)"""
    try:
        logger.info(f"Azure AI Search ì—°ê²° ì‹œë„: endpoint={AZURE_SEARCH_ENDPOINT}, index={AZURE_SEARCH_INDEX}, ë¬¸ì„œìˆ˜={len(articles)}")
        search_client = SearchClient(
            endpoint=str(AZURE_SEARCH_ENDPOINT),
            index_name=str(AZURE_SEARCH_INDEX),
            credential=AzureKeyCredential(str(AZURE_SEARCH_API_KEY))
        )
        if articles:
            logger.info(f"ìƒ˜í”Œ ë¬¸ì„œ êµ¬ì¡°: { {k:type(v).__name__ for k,v in articles[0].items()} }")
        logger.info("ğŸš€ ì—…ë¡œë“œ ì‹œì‘...")
        result = search_client.upload_documents(articles)
        success_count = len([r for r in result if r.succeeded])
        failed_count = len([r for r in result if not r.succeeded])
        logger.info(f"âœ… {success_count}ê°œ ê¸°ì‚¬ ì—…ë¡œë“œ ì„±ê³µ, âŒ {failed_count}ê°œ ì‹¤íŒ¨")
        if failed_count > 0:
            for r in result:
                if not r.succeeded:
                    logger.warning(f"ì‹¤íŒ¨ ë¬¸ì„œ {r.key}: {r.error_message}")
        return success_count > 0
    except Exception as e:
        logger.error(f"Azure AI Search ì—…ë¡œë“œ ì˜¤ë¥˜: {e}", exc_info=True)
        return False

async def extract_keywords_with_gpt4o(articles):
    """Azure OpenAI GPT-4oë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    
    try:
        articles_text = "\n".join([
            f"ì œëª©: {article['title']}\në‚´ìš©: {article['content'][:200]}..."
            for article in articles[:50]
        ])
        
        prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•˜ê³  ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ê¸°ì‚¬ ë‚´ìš©:
{articles_text}

ìš”êµ¬ì‚¬í•­:
1. ê¸°ì—…ëª…ì€ ì œì™¸í•˜ê³  ê¸°ìˆ /ì‚°ì—… ê´€ë ¨ í‚¤ì›Œë“œ ìš°ì„  ì¶”ì¶œ
2. ê¸°ì‚¬ì—ì„œ ìì£¼ ì–¸ê¸‰ë˜ëŠ” ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
3. ì‘ë‹µ í˜•ì‹: í‚¤ì›Œë“œ1:ë¹ˆë„1, í‚¤ì›Œë“œ2:ë¹ˆë„2 (ì½¤ë§ˆ êµ¬ë¶„)
4. ë¹ˆë„ëŠ” 5-25 ë²”ìœ„
5. ìµœì†Œ 5ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ

ì£¼ìš” í‚¤ì›Œë“œ:
"""
        
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê¸°ì‚¬ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.2
        )
        
        keywords_text = response.choices[0].message.content or ""
        print(f"GPT-4o ì‘ë‹µ: {keywords_text}")
        
        # í‚¤ì›Œë“œ íŒŒì‹±
        keywords = []
        for item in keywords_text.split(','):
            if ':' in item:
                parts = item.strip().split(':', 1)
                keyword = parts[0].strip()
                try:
                    count = int(parts[1].strip())
                    keywords.append({"keyword": keyword, "count": count})
                except:
                    keywords.append({"keyword": keyword, "count": 10})
        
        # í‚¤ì›Œë“œê°€ ì¶”ì¶œë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ í‚¤ì›Œë“œ ì œê³µ
        if not keywords:
            print("âš ï¸ GPT-4oì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©")
            keywords = [
                {"keyword": "IT", "count": 20},
                {"keyword": "ê¸°ìˆ ", "count": 18},
                {"keyword": "ë””ì§€í„¸", "count": 15},
                {"keyword": "ì •ë³´", "count": 12},
                {"keyword": "ì‹œìŠ¤í…œ", "count": 10}
            ]
        
        # ë¹ˆë„ ê¸°ì¤€ ì •ë ¬
        keywords.sort(key=lambda x: x['count'], reverse=True)
        
        print(f"âœ… {len(keywords)}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
        return keywords
        
    except Exception as e:
        print(f"âŒ GPT-4o ì˜¤ë¥˜: {e}")
        return []

# ìƒˆë¡œìš´ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ - ì‹œê°ë³„ ë¶„ì„ê³¼ ì±—ë´‡ ê¸°ëŠ¥


from fastapi import Request
from fastapi.responses import JSONResponse

@app.post("/chat")
async def chat(request: Request):
    """ì‚°ì—…ë³„ í‚¤ì›Œë“œ ë¶„ì„ ê¸°ë°˜ ë™ì  ì±—ë´‡"""
    try:
        data = await request.json()
        question = data.get("question") or data.get("message") or ""
        if not question:
            return JSONResponse(content={"answer": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."})
        # 1. ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì‚°ì—… ë¶„ë¥˜
        keyword_info = extract_keyword_and_industry(question)
        # 2. í˜„ì¬ ì£¼ê°„ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
        current_keywords = get_current_weekly_keywords()
        # 3. ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ë™ì  ì‘ë‹µ
        if keyword_info["type"] == "industry_analysis":
            answer = generate_industry_based_answer(
                question,
                keyword_info["keyword"],
                keyword_info["industry"],
                current_keywords
            )
        elif keyword_info["type"] == "keyword_trend":
            answer = generate_keyword_trend_answer(question, keyword_info["keyword"])
        elif keyword_info["type"] == "comparison":
            answer = generate_comparison_answer(question, keyword_info["keywords"])
        else:
            answer = generate_contextual_answer(question, current_keywords)
        return JSONResponse(content={"answer": answer})
    except Exception as e:
        logger.error(f"/chat ì˜¤ë¥˜: {e}", exc_info=True)
        return JSONResponse(content={"answer": f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}, status_code=500)

def extract_keyword_and_industry(question):
    """ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œì™€ ì‚°ì—… ë¶„ë¥˜ ì¶”ì¶œ"""
    
    # ì‚°ì—… ê´€ë ¨ í‚¤ì›Œë“œ ë§¤í•‘
    industry_keywords = {
        "ì‚¬íšŒ": ["ì‚¬íšŒ", "êµìœ¡", "ì¼ìë¦¬", "ë³µì§€", "ì •ì±…", "ì œë„", "ì‹œë¯¼", "ê³µê³µ"],
        "ê²½ì œ": ["ê²½ì œ", "ì‹œì¥", "íˆ¬ì", "ê¸ˆìœµ", "ì£¼ê°€", "ë¹„ìš©", "ìˆ˜ìµ", "ë§¤ì¶œ", "ê¸°ì—…"],
        "IT/ê³¼í•™": ["ê¸°ìˆ ", "ê°œë°œ", "í˜ì‹ ", "ì—°êµ¬", "ê³¼í•™", "IT", "ì†Œí”„íŠ¸ì›¨ì–´", "í•˜ë“œì›¨ì–´", "í”Œë«í¼"],
        "ìƒí™œ/ë¬¸í™”": ["ìƒí™œ", "ë¬¸í™”", "ë¼ì´í”„ìŠ¤íƒ€ì¼", "ì†Œë¹„", "íŠ¸ë Œë“œ", "ì¼ìƒ", "ì—¬ê°€", "ì—”í„°í…Œì¸ë¨¼íŠ¸"],
        "ì„¸ê³„": ["ê¸€ë¡œë²Œ", "êµ­ì œ", "ì„¸ê³„", "í•´ì™¸", "ìˆ˜ì¶œ", "í˜‘ë ¥", "ê²½ìŸ", "í‘œì¤€"]
    }
    
    question_lower = question.lower()
    
    # ì‚°ì—… ë¶„ë¥˜ ì¶”ì¶œ
    detected_industry = None
    for industry, keywords in industry_keywords.items():
        if any(keyword in question_lower for keyword in keywords):
            detected_industry = industry
            break
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)
    # í˜„ì¬ ì£¼ê°„ í‚¤ì›Œë“œì™€ ë§¤ì¹˜ë˜ëŠ” ê²ƒ ì°¾ê¸°
    current_keywords = get_current_weekly_keywords()
    detected_keyword = None
    for keyword in current_keywords:
        if keyword in question or keyword.lower() in question_lower:
            detected_keyword = keyword
            break
    
    # ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
    if detected_industry and detected_keyword:
        question_type = "industry_analysis"
    elif "vs" in question_lower or "ë¹„êµ" in question_lower or "ì°¨ì´" in question_lower:
        question_type = "comparison"
        # ë¹„êµ ëŒ€ìƒ í‚¤ì›Œë“œë“¤ ì¶”ì¶œ
        comparison_keywords = [kw for kw in current_keywords if kw.lower() in question_lower]
        return {
            "type": question_type,
            "keywords": comparison_keywords,
            "industry": detected_industry,
            "keyword": detected_keyword
        }
    elif detected_keyword:
        question_type = "keyword_trend"
    else:
        question_type = "general"
    
    return {
        "type": question_type,
        "keyword": detected_keyword,
        "industry": detected_industry or "ì‚¬íšŒ"  # ê¸°ë³¸ê°’
    }

def get_current_weekly_keywords():
    """í˜„ì¬ ì£¼ê°„ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°"""
    try:
        # ì§ì ‘ì ì¸ í‚¤ì›Œë“œ ë¶„ì„ ëŒ€ì‹  í˜„ì¬ ì£¼ì°¨ì˜ ëŒ€í‘œ í‚¤ì›Œë“œ ë°˜í™˜
        return ["ì¸ê³µì§€ëŠ¥", "ë°˜ë„ì²´", "ê¸°ìˆ í˜ì‹ "]
    except Exception as e:
        print(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return ["ì¸ê³µì§€ëŠ¥", "ë°˜ë„ì²´", "ê¸°ì—…"]

def generate_industry_based_answer(question, keyword, industry, current_keywords):
    """ì‚°ì—…ë³„ í‚¤ì›Œë“œ ë¶„ì„ ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
    try:
        # ì‚°ì—…ë³„ ê´€ì  ì •ì˜
        industry_context = {
            "ì‚¬íšŒ": "ì‚¬íšŒì  ì˜í–¥, ì •ì±…ì  ì¸¡ë©´, ì‹œë¯¼ ìƒí™œ ë³€í™”",
            "ê²½ì œ": "ê²½ì œì  íŒŒê¸‰íš¨ê³¼, ì‹œì¥ ë™í–¥, íˆ¬ì ê´€ì ",
            "IT/ê³¼í•™": "ê¸°ìˆ ì  í˜ì‹ , ì—°êµ¬ê°œë°œ ë™í–¥, ê¸°ìˆ ì  ê³¼ì œ",
            "ìƒí™œ/ë¬¸í™”": "ì¼ìƒìƒí™œ ë³€í™”, ë¬¸í™”ì  ìˆ˜ìš©ì„±, ì†Œë¹„ì í–‰ë™",
            "ì„¸ê³„": "ê¸€ë¡œë²Œ íŠ¸ë Œë“œ, êµ­ì œ ê²½ìŸ, í•´ì™¸ ë™í–¥"
        }
        
        context_desc = industry_context.get(industry, "ì „ë°˜ì ì¸ ê´€ì ")
        
        prompt = f"""
ì§ˆë¬¸: {question}
í‚¤ì›Œë“œ: {keyword}
ê´€ì : {industry} ({context_desc})
í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œ: {', '.join(current_keywords)}

{industry} ê´€ì ì—ì„œ '{keyword}'ì— ëŒ€í•´ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€ í˜•ì‹:
1. {industry} ê´€ì ì—ì„œ ë³¸ '{keyword}'ì˜ í˜„ì¬ ìƒí™©
2. ì£¼ìš” ë™í–¥ê³¼ ë³€í™”
3. ì „ë§ê³¼ ì‹œì‚¬ì 

êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        
        completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"ë‹¹ì‹ ì€ {industry} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ {industry} ê´€ì ì—ì„œ í‚¤ì›Œë“œì— ëŒ€í•´ ë¶„ì„í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500
        )
        
        return completion.choices[0].message.content
        
    except Exception as e:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. {industry} ê´€ì ì—ì„œì˜ '{keyword}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_keyword_trend_answer(question, keyword):
    """í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ ë‹µë³€ ìƒì„±"""
    try:
        prompt = f"""
ì§ˆë¬¸: {question}
í‚¤ì›Œë“œ: {keyword}

'{keyword}'ì˜ ìµœê·¼ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¶„ì„ ë‚´ìš©:
1. ìµœê·¼ '{keyword}' ê´€ë ¨ ì£¼ìš” ë‰´ìŠ¤ ë™í–¥
2. ì‹œê°„ì  ë³€í™”ì™€ ë°œì „ ë°©í–¥
3. í–¥í›„ ì „ë§ê³¼ ê´€ì‹¬ í¬ì¸íŠ¸

ì‹œê°„ìˆœìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ íŠ¸ë Œë“œë¥¼ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
        
        completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"ë‹¹ì‹ ì€ '{keyword}' ë¶„ì•¼ì˜ íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìµœì‹  ë™í–¥ê³¼ ë³€í™”ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500
        )
        
        return completion.choices[0].message.content
        
    except Exception as e:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{keyword}' íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_comparison_answer(question, keywords):
    """ë¹„êµ ë¶„ì„ ë‹µë³€ ìƒì„±"""
    try:
        prompt = f"""
ì§ˆë¬¸: {question}
ë¹„êµ ëŒ€ìƒ: {', '.join(keywords)}

í‚¤ì›Œë“œë“¤ì„ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¹„êµ ë¶„ì„ ë‚´ìš©:
1. ê° í‚¤ì›Œë“œì˜ í˜„ì¬ ìƒí™©ê³¼ íŠ¹ì§•
2. ê³µí†µì ê³¼ ì°¨ì´ì 
3. ìƒí˜¸ ê´€ê³„ì™€ ì˜í–¥
4. ê°ê°ì˜ ì „ë§ê³¼ ì¤‘ìš”ì„±

ê°ê´€ì ì´ê³  ê· í˜•ì¡íŒ ì‹œê°ìœ¼ë¡œ ë¹„êµí•´ì£¼ì„¸ìš”.
"""
        
        completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ í‚¤ì›Œë“œë¥¼ ë¹„êµ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ìœ¼ë¡œ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=600
        )
        
        return completion.choices[0].message.content
        
    except Exception as e:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. í‚¤ì›Œë“œ ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_contextual_answer(question, current_keywords):
    """í˜„ì¬ í‚¤ì›Œë“œ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¼ë°˜ ë‹µë³€ ìƒì„±"""
    try:
        # í˜„ì¬ ì£¼ê°„ í‚¤ì›Œë“œ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        keywords_context = f"í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œ: {', '.join(current_keywords)}"
        
        prompt = f"""
ì§ˆë¬¸: {question}
{keywords_context}

í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œë“¤ê³¼ ì—°ê´€ì§€ì–´ ë‹µë³€í•˜ë˜, ì§ˆë¬¸ì˜ ë§¥ë½ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€ ì‹œ ê³ ë ¤ì‚¬í•­:
1. í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œì™€ì˜ ì—°ê´€ì„± ì–¸ê¸‰
2. êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ë°ì´í„° í™œìš©  
3. ê· í˜•ì¡íŒ ì‹œê°ìœ¼ë¡œ ì„¤ëª…
4. ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ

ëª…í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œ({', '.join(current_keywords)})ë¥¼ ê³ ë ¤í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=400
        )
        
        return completion.choices[0].message.content
        
    except Exception as e:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

@app.get("/weekly-keywords")
def get_weekly_keywords():
    """ì£¼ê°„ Top 3 í‚¤ì›Œë“œ ë°˜í™˜"""
    try:
        # ìƒ˜í”Œ í‚¤ì›Œë“œ (ì‹¤ì œë¡œëŠ” DeepSearch APIë‚˜ ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        response_data = {
            "keywords": ["ì¸ê³µì§€ëŠ¥", "ë°˜ë„ì²´", "ê¸°ìˆ í˜ì‹ "],
            "week_info": "7ì›” 3ì£¼ì°¨ (2025.07.14~07.18) - AI ë‰´ìŠ¤ ë¶„ì„"
        }
        return JSONResponse(content=response_data, media_type="application/json; charset=utf-8")
    except Exception as e:
        response_data = {
            "keywords": ["ì¸ê³µì§€ëŠ¥", "ë°˜ë„ì²´", "ê¸°ì—…"],
            "week_info": "7ì›” 3ì£¼ì°¨ (2025.07.14~07.18) - AI ë‰´ìŠ¤ ë¶„ì„"
        }
        return JSONResponse(content=response_data, media_type="application/json; charset=utf-8")

def get_sample_keywords_by_date(start_date: str, end_date: str):
    """ë‚ ì§œì— ë”°ë¥¸ ìƒ˜í”Œ í‚¤ì›Œë“œ ë°˜í™˜"""
    if "07-01" in start_date:  # 7ì›” 1ì£¼ì°¨
        return ["ì „ê¸°ì°¨", "ë°°í„°ë¦¬", "ì¶©ì „ì¸í”„ë¼"]
    elif "07-06" in start_date:  # 7ì›” 2ì£¼ì°¨  
        return ["ë©”íƒ€ë²„ìŠ¤", "VR", "ê°€ìƒí˜„ì‹¤"]
    elif "07-14" in start_date:  # 7ì›” 3ì£¼ì°¨
        return ["ì •ë³´í†µì‹ ì‚°ì—…ì§„í¥ì›", "AI Youth Festa 2025", "ì¸ê³µì§€ëŠ¥"]
    else:
        return ["ê¸°ìˆ ", "í˜ì‹ ", "ë””ì§€í„¸"]

@app.post("/industry-analysis")
def get_industry_analysis(request: dict):
    """ì‚°ì—…ë³„ í‚¤ì›Œë“œ ë¶„ì„ (ê¸°ì¡´ + ì •ë°˜ëŒ€ ê´€ì )"""
    industry = request.get("industry", "")
    keyword = request.get("keyword", "")
    
    if not industry or not keyword:
        raise HTTPException(status_code=400, detail="ì‚°ì—…ê³¼ í‚¤ì›Œë“œë¥¼ ëª¨ë‘ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
    
    # ê¸°ì¡´ ë¶„ì„ í”„ë¡¬í”„íŠ¸
    industry_prompts = {
        "ì‚¬íšŒ": f"'{keyword}'ì— ëŒ€í•œ ì‚¬íšŒì  ê´€ì ì—ì„œì˜ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”. ì‚¬íšŒ êµ¬ì¡°, ì‹œë¯¼ ìƒí™œ, ì‚¬íšŒ ë¬¸ì œ í•´ê²° ë“±ì˜ ì¸¡ë©´ì—ì„œ 3-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ê²½ì œ": f"'{keyword}'ì— ëŒ€í•œ ê²½ì œì  ê´€ì ì—ì„œì˜ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”. ì‹œì¥ ì˜í–¥, íˆ¬ì ì „ë§, ì‚°ì—… íŒŒê¸‰íš¨ê³¼ ë“±ì˜ ì¸¡ë©´ì—ì„œ 3-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "IT/ê³¼í•™": f"'{keyword}'ì— ëŒ€í•œ IT/ê³¼í•™ ê¸°ìˆ ì  ê´€ì ì—ì„œì˜ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”. ê¸°ìˆ  ë°œì „, í˜ì‹  ë™í–¥, ê¸°ìˆ ì  ê³¼ì œ ë“±ì˜ ì¸¡ë©´ì—ì„œ 3-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ìƒí™œ/ë¬¸í™”": f"'{keyword}'ì— ëŒ€í•œ ìƒí™œ/ë¬¸í™”ì  ê´€ì ì—ì„œì˜ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”. ì¼ìƒ ìƒí™œ ë³€í™”, ë¬¸í™”ì  ì˜í–¥, ë¼ì´í”„ìŠ¤íƒ€ì¼ ë“±ì˜ ì¸¡ë©´ì—ì„œ 3-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ì„¸ê³„": f"'{keyword}'ì— ëŒ€í•œ ê¸€ë¡œë²Œ/êµ­ì œì  ê´€ì ì—ì„œì˜ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”. êµ­ì œ ë™í–¥, ê¸€ë¡œë²Œ ê²½ìŸ, ì™¸êµì  ì˜í–¥ ë“±ì˜ ì¸¡ë©´ì—ì„œ 3-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    }
    
    # ì •ë°˜ëŒ€ ê´€ì  í”„ë¡¬í”„íŠ¸
    counter_prompts = {
        "ì‚¬íšŒ": f"'{keyword}'ì— ëŒ€í•œ ë¹„íŒì /íšŒì˜ì  ì‚¬íšŒ ê´€ì ì„ ì œì‹œí•´ì£¼ì„¸ìš”. ì‚¬íšŒì  ìš°ë ¤, ë¶€ì‘ìš©, ê²©ì°¨ ì‹¬í™” ë“±ì˜ ì¸¡ë©´ì—ì„œ 3-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ê²½ì œ": f"'{keyword}'ì— ëŒ€í•œ ê²½ì œì  ë¦¬ìŠ¤í¬ì™€ ë¶€ì •ì  ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. ì‹œì¥ ë¶ˆì•ˆì •ì„±, íˆ¬ì ìœ„í—˜, ê²½ì œì  ë¶€ì‘ìš© ë“±ì˜ ì¸¡ë©´ì—ì„œ 3-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "IT/ê³¼í•™": f"'{keyword}'ì— ëŒ€í•œ ê¸°ìˆ ì  í•œê³„ì™€ ë¬¸ì œì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. ê¸°ìˆ ì  ìœ„í—˜, ìœ¤ë¦¬ì  ë¬¸ì œ, ë°œì „ ì¥ì• ë¬¼ ë“±ì˜ ì¸¡ë©´ì—ì„œ 3-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ìƒí™œ/ë¬¸í™”": f"'{keyword}'ì— ëŒ€í•œ ë¬¸í™”ì  ì €í•­ê³¼ ìƒí™œìƒì˜ ë¬¸ì œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. ì „í†µ ë¬¸í™” ì¶©ëŒ, ìƒí™œ ë¶ˆí¸, ë¬¸í™”ì  ë¶€ì‘ìš© ë“±ì˜ ì¸¡ë©´ì—ì„œ 3-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ì„¸ê³„": f"'{keyword}'ì— ëŒ€í•œ êµ­ì œì  ê°ˆë“±ê³¼ ë¶€ì •ì  ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. êµ­ê°€ê°„ ë¶„ìŸ, ê¸€ë¡œë²Œ ë¶ˆí‰ë“±, êµ­ì œì  ìš°ë ¤ ë“±ì˜ ì¸¡ë©´ì—ì„œ 3-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    }
    
    main_prompt = industry_prompts.get(industry, f"'{keyword}'ì— ëŒ€í•œ {industry} ê´€ì ì—ì„œì˜ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.")
    counter_prompt = counter_prompts.get(industry, f"'{keyword}'ì— ëŒ€í•œ {industry} ê´€ì ì—ì„œì˜ ë°˜ëŒ€ ì˜ê²¬ì„ ì œê³µí•´ì£¼ì„¸ìš”.")
    
    try:
        # ê¸°ì¡´ ë¶„ì„
        main_completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"{industry} ë¶„ì•¼ ì „ë¬¸ê°€ë¡œì„œ í‚¤ì›Œë“œì— ëŒ€í•œ ê¸ì •ì  ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": main_prompt}
            ]
        )
        
        # ì •ë°˜ëŒ€ ê´€ì  ë¶„ì„
        counter_completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"{industry} ë¶„ì•¼ì˜ ë¹„íŒì  ì‹œê°ì„ ê°€ì§„ ì „ë¬¸ê°€ë¡œì„œ ë°˜ëŒ€ ì˜ê²¬ì„ ì œì‹œí•©ë‹ˆë‹¤."},
                {"role": "user", "content": counter_prompt}
            ]
        )
        
        return {
            "analysis": main_completion.choices[0].message.content,
            "counter_analysis": counter_completion.choices[0].message.content
        }
    except Exception as e:
        return {
            "analysis": f"ë¶„ì„ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "counter_analysis": "ë°˜ëŒ€ ì˜ê²¬ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }

@app.post("/chat")
def chat(query: dict):
    """ì‚°ì—…ë³„ í‚¤ì›Œë“œ ë¶„ì„ ê¸°ë°˜ ë™ì  ì±—ë´‡"""
    question = query.get("question", "")
    
    if not question:
        return {"answer": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}
    
    try:
        # ê°„ë‹¨í•œ ë‹µë³€ ìƒì„±
        completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œëŠ” 'ì •ë³´í†µì‹ ì‚°ì—…ì§„í¥ì›', 'AI Youth Festa 2025', 'ì¸ê³µì§€ëŠ¥'ì…ë‹ˆë‹¤."},
                {"role": "user", "content": question}
            ],
            max_tokens=300
        )
        
        return {"answer": completion.choices[0].message.content}
        
    except Exception as e:
        return {"answer": f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

@app.post("/keyword-analysis")
def analyze_keyword_dynamically(request: dict):
    """ë™ì  í‚¤ì›Œë“œ ë¶„ì„ - í´ë¦­ëœ í‚¤ì›Œë“œì— ëŒ€í•œ ë‹¤ê°ë„ ë¶„ì„"""
    keyword = request.get("keyword", "")
    
    if not keyword:
        raise HTTPException(status_code=400, detail="í‚¤ì›Œë“œë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
    
    try:
        # í‚¤ì›Œë“œì— ëŒ€í•œ ë‹¤ê°ë„ ë¶„ì„
        prompt = f"""
í‚¤ì›Œë“œ: '{keyword}'

ë‹¤ìŒ 5ê°€ì§€ ê´€ì ì—ì„œ ì´ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì‚¬íšŒì  ì˜í–¥
2. ê²½ì œì  ì¸¡ë©´  
3. ê¸°ìˆ ì  ê´€ì 
4. ë¬¸í™”ì  ì˜ë¯¸
5. ë¯¸ë˜ ì „ë§

ê° ê´€ì ë³„ë¡œ 2-3ë¬¸ì¥ì”© ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
        
        completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500
        )
        
        return {
            "keyword": keyword,
            "analysis": completion.choices[0].message.content
        }
        
    except Exception as e:
        return {
            "keyword": keyword,
            "analysis": f"í‚¤ì›Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)