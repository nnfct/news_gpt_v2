import logging
import re
import asyncio
from typing import List, Dict, Any, Optional
from fastapi import HTTPException
from core.config import openai_client, openai_keyword_explainer_client, ncs_search_client, AZURE_OPENAI_DEPLOYMENT, AZURE_OPENAI_DEPLOYMENT_NCS, AZURE_OPENAI_KEYWORD_EXPLAINER_DEPLOYMENT

logger = logging.getLogger(__name__)

async def search_ncs_documents(query, top_k=3):
    """Azure AI Searchì—ì„œ NCS ì§ë¬´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ê´€ë ¨ ë¬¸ì„œ ë°˜í™˜"""
    if not ncs_search_client:
        logger.warning("NCS Search Clientê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìƒ˜í”Œ NCS ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return [
            {"title": "ìƒ˜í”Œ NCS ì§ë¬´: ì¸ê³µì§€ëŠ¥ ê°œë°œì", "content": "ì¸ê³µì§€ëŠ¥ ê°œë°œìëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì„¤ê³„, ë°ì´í„° ë¶„ì„, AI ì‹œìŠ¤í…œ êµ¬ì¶• ë“±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìš”êµ¬ ì—­ëŸ‰ìœ¼ë¡œëŠ” íŒŒì´ì¬, ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ ì´í•´, ë°ì´í„° ê³¼í•™ ì§€ì‹ ë“±ì´ ìˆìŠµë‹ˆë‹¤.", "source": "NCS ìƒ˜í”Œ"},
            {"title": "ìƒ˜í”Œ NCS ì§ë¬´: ë¹…ë°ì´í„° ë¶„ì„ê°€", "content": "ë¹…ë°ì´í„° ë¶„ì„ê°€ëŠ” ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘, ì €ì¥, ì²˜ë¦¬, ë¶„ì„í•˜ì—¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤. í†µê³„í•™, í”„ë¡œê·¸ë˜ë°, ë°ì´í„°ë² ì´ìŠ¤ ì§€ì‹ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.", "source": "NCS ìƒ˜í”Œ"}
        ]

    try:
        logger.info(f"ğŸ” Azure AI Searchì—ì„œ NCS ë°ì´í„° ê²€ìƒ‰ ì¤‘: '{query}'")
        search_results = await asyncio.to_thread(
            ncs_search_client.search,
            search_text=query,
            query_type="semantic",
            semantic_configuration_name="default",
            search_fields=["content"],
            top=top_k
        )

        docs = []
        for result in search_results:
            docs.append(result.get("content", result.get("text", result.get("description", "ë‚´ìš© ì—†ìŒ"))))

        return "\n\n---\n\n".join(docs)
    except Exception as e:
        logger.error(f"âŒ Azure AI Search NCS ê²€ìƒ‰ ì˜¤ë¥˜: {e}", exc_info=True)
        return ""

async def get_job_industry_summary(query: str) -> str:
    """ì‚¬ìš©ì ì§ˆë¬¸ì— ê¸°ë°˜í•˜ì—¬ NCS ì§ë¬´/ì‚°ì—… ì •ë³´ ìš”ì•½ (AI í™œìš©)"""
    logger.info(f"ğŸ§  get_job_industry_summary í˜¸ì¶œ - ì¿¼ë¦¬: {query}")
    context_text = await search_ncs_documents(query)

    if not context_text:
        logger.warning("â— ê´€ë ¨ëœ ì§ë¬´/ì‚°ì—… ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¼ë°˜ GPT ë‹µë³€ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        system_msg = "ë„ˆëŠ” ì§ë¬´/ì‚°ì—… ê´€ë ¨ ì „ë¬¸ê°€ AIì•¼."
        user_prompt = f"'{query}'ì— ëŒ€í•´ ê°„ëµí•˜ê²Œ ìš”ì•½í•´ì¤˜."
        try:
            response = openai_client.chat.completions.create(
                model=AZURE_OPENAI_DEPLOYMENT_NCS,
                messages=[
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.4,
                max_tokens=1500
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            logger.error(f"âŒ ìƒ˜í”Œ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            return "ê´€ë ¨ëœ ì§ë¬´/ì‚°ì—… ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê³ , ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    system_msg = "ë„ˆëŠ” ì§ë¬´/ì‚°ì—… ê´€ë ¨ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ëŠ” AI ì§ë¬´ ë¶„ì„ê°€ì•¼. NCS ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´."
    user_prompt = f"""
    ë„ˆëŠ” ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ë¬´/ì‚°ì—… í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ,
    Azure Searchì— ì €ì¥ëœ NCS ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ìš”ì•½í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤.

    - ì•„ë˜ ê²°ê³¼ëŠ” Azure Searchë¥¼ í†µí•´ ê²€ìƒ‰ëœ ë¬¸ì„œì´ë‹¤. ë°˜ë“œì‹œ ì´ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì •ë¦¬í•  ê²ƒ.
    - ê²°ê³¼ê°€ ì—†ìœ¼ë©´ â€œì—†ë‹¤â€ê³  í•˜ì§€ ë§ê³ , ê°€ëŠ¥í•œ ìœ ì‚¬ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ ìœ ì¶”í•˜ë¼.

    [ì‚¬ìš©ì ì…ë ¥]
    {query}

    [Azure Search ê²€ìƒ‰ ê²°ê³¼]
    {context_text}

    [ìš”ì•½ í˜•ì‹]
    ---
    ğŸ”§ ì§ë¬´ ê°œìš”  
    ğŸ“š ìš”êµ¬ ì§€ì‹  
    ğŸ›  ìš”êµ¬ ê¸°ìˆ   
    ğŸ¤ ìš”êµ¬ íƒœë„
    """

    try:
        response = openai_client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT_NCS,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.4,
            max_tokens=1500
        )
        summary = response.choices[0].message.content.strip()
        logger.info(f"âœ… NCS ìš”ì•½ ì„±ê³µ. ê¸¸ì´: {len(summary)}")
        return summary
    except Exception as e:
        logger.error(f"âŒ NCS ì§ë¬´ ìš”ì•½ ì˜¤ë¥˜: {e}", exc_info=True)
        return "NCS ì§ë¬´ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API ì—°ê²° ë˜ëŠ” ëª¨ë¸ ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”."

async def extract_keywords_with_gpt(articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """GPTë¥¼ ì‚¬ìš©í•´ ê¸°ì‚¬ë“¤ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³ , ê° í‚¤ì›Œë“œ ì„ ì • ì´ìœ ë¥¼ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not articles:
        logger.warning("âŒ ë¶„ì„í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
        return []

    try:
        top_articles = articles[:10]
        titles_text = "\n".join([f"- {article['title']}" for article in top_articles])

        prompt = f"""ë‹¤ìŒ ITê¸°ìˆ  ë‰´ìŠ¤ ì œëª©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 5ê°œë¥¼ ì¶”ì¶œí•˜ê³ , ê° í‚¤ì›Œë“œê°€ **í˜„ì¬ ë‰´ìŠ¤ì—ì„œ ì£¼ëª©ë°›ëŠ” êµ¬ì²´ì ì¸ ë°°ê²½ì´ë‚˜ ë™í–¥ì„ í¬í•¨í•˜ì—¬ ì„ ì • ì´ìœ ë¥¼ ìƒì„¸íˆ ì„¤ëª…**í•˜ì„¸ìš”.

ë‰´ìŠ¤ ì œëª©:
{titles_text}

ì¤‘ìš”: ë§ˆí¬ë‹¤ìš´ í—¤ë”(#) ì‚¬ìš© ê¸ˆì§€.
í˜•ì‹:
í‚¤ì›Œë“œ1: ì„ ì • ì´ìœ 1
í‚¤ì›Œë“œ2: ì„ ì • ì´ìœ 2
í‚¤ì›Œë“œ3: ì„ ì • ì´ìœ 3
í‚¤ì›Œë“œ4: ì„ ì • ì´ìœ 4
í‚¤ì›Œë“œ5: ì„ ì • ì´ìœ 5
"""
        response = openai_client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=[
                {"role": "system", "content": "ITê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ ì „ë¬¸ê°€. ê° í‚¤ì›Œë“œë¥¼ ì„ ì •í•œ í•µì‹¬ ì´ìœ ë¥¼ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´ í—¤ë” ì‚¬ìš© ê¸ˆì§€."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1500,
            temperature=0.2
        )

        keywords_with_reasons_text = response.choices[0].message.content or ""
        logger.info(f"ğŸš€ GPT í‚¤ì›Œë“œ ë° ì´ìœ  ì¶”ì¶œ ì™„ë£Œ: \n{keywords_with_reasons_text}")

        keywords = []
        
        processed_text = re.sub(
            r'(í‚¤ì›Œë“œ(\d+):\s*(.+?))\n\s*(ì„ ì • ì´ìœ \2:\s*(.+?))',
            r'\1 \4',
            keywords_with_reasons_text,
            flags=re.IGNORECASE | re.DOTALL
        )

        lines = processed_text.strip().split('\n')
        filtered_lines = [line.strip() for line in lines if line.strip()]

        for i, line in enumerate(filtered_lines):
            keyword_raw = ""
            reason = "ì´ìœ  ì—†ìŒ"

            if ':' in line:
                first_colon_idx = line.find(':')
                keyword_part = line[:first_colon_idx].strip()
                rest_of_line = line[first_colon_idx+1:].strip()

                reason_match = re.search(r'ì„ ì • ì´ìœ \d+:\s*(.+)', rest_of_line, re.IGNORECASE)
                if reason_match:
                    reason = reason_match.group(1).strip()
                    keyword_raw = re.sub(r'ì„ ì • ì´ìœ \d+:\s*.+', '', rest_of_line, re.IGNORECASE).strip()
                else:
                    reason = rest_of_line
                    keyword_raw = keyword_part
            else:
                keyword_raw = line.strip()
                reason = "GPTê°€ ì„ ì • ì´ìœ ë¥¼ ì œê³µí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

            keyword_final = re.sub(r'^(í‚¤ì›Œë“œ\d+|Keyword\d+|\d+\.)\s*', '', keyword_raw, flags=re.IGNORECASE).strip()
            keyword_final = re.sub(r'^[^\w\s]*', '', keyword_final).strip()
            keyword_final = re.sub(r'[^\w\s\-/ê°€-í£]', '', keyword_final).strip()
            keyword_final = re.sub(r'[:.]$', '', keyword_final).strip()

            if keyword_final and 2 <= len(keyword_final) <= 30:
                keywords.append({
                    "keyword": keyword_final,
                    "reason": reason,
                    "count": 30 - (len(keywords) * 5),
                    "rank": len(keywords) + 1
                })
                if len(keywords) >= 5:
                    break
            else:
                logger.warning(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ í‚¤ì›Œë“œ íŒŒì‹±ë¨: ì›ë³¸:'{line}', í›„ë³´:'{keyword_raw}', ìµœì¢…:'{keyword_final}' (ê¸¸ì´/ì¡°ê±´ ë¶ˆì¶©ì¡±)")

        if len(keywords) < 3:
            logger.warning("âš ï¸ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë¶€ì¡±, ê¸°ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©")
            keywords = [
                {"keyword": "ì¸ê³µì§€ëŠ¥", "reason": "GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ í‚¤ì›Œë“œ", "count": 25, "rank": 1},
                {"keyword": "ë°˜ë„ì²´", "reason": "GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ í‚¤ì›Œë“œ", "count": 20, "rank": 2},
                {"keyword": "í´ë¼ìš°ë“œ", "reason": "GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ í‚¤ì›Œë“œ", "count": 15, "rank": 3},
                {"keyword": "ë¹…ë°ì´í„°", "reason": "GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ í‚¤ì›Œë“œ", "count": 10, "rank": 4},
                {"keyword": "ë¡œë´‡", "reason": "GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ í‚¤ì›Œë“œ", "count": 5, "rank": 5}
            ]
        
        return keywords

    except Exception as e:
        logger.error(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
        return [
            {"keyword": "ì¸ê³µì§€ëŠ¥", "reason": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ìƒ˜í”Œ ë°ì´í„°", "count": 25, "rank": 1},
            {"keyword": "ë°˜ë„ì²´", "reason": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ìƒ˜í”Œ ë°ì´í„°", "count": 20, "rank": 2},
            {"keyword": "í´ë¼ìš°ë“œ", "reason": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ìƒ˜í”Œ ë°ì´í„°", "count": 15, "rank": 3}
        ]

async def extract_global_keywords_with_gpt(articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """GPTë¥¼ ì‚¬ìš©í•´ í•´ì™¸ ê¸°ì‚¬ë“¤ì—ì„œ ì˜ì–´ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³ , ê° í‚¤ì›Œë“œ ì„ ì • ì´ìœ ë¥¼ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not articles:
        logger.warning("âŒ ë¶„ì„í•  í•´ì™¸ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
        return []
    
    try:
        top_articles = articles[:10]
        titles_text = "\n".join([f"- {article['title']}" for article in top_articles])

        prompt = f"""Extract 5 key English tech keywords from these global news titles:
For each keyword, provide a **detailed reason explaining its current prominence or relevant trend in the news.**

News Titles:
{titles_text}

Requirements:
- Only English words
- Tech/Technology focused
- No Korean words
- No markdown headers (#)
- Plain text only
Format:
Keyword1: Reason1
Keyword2: Reason2
Keyword3: Reason3
Keyword4: Reason4
Keyword5: Reason5
"""
        response = openai_client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=[
                {"role": "system", "content": "You are an expert at extracting English tech keywords from global news. Provide concise reasons for each keyword. Use plain text only, no markdown headers."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1500,
            temperature=0.2
        )
        
        keywords_with_reasons_text = response.choices[0].message.content or ""
        logger.info(f"ğŸŒ í•´ì™¸ GPT í‚¤ì›Œë“œ ë° ì´ìœ  ì¶”ì¶œ ì™„ë£Œ: \n{keywords_with_reasons_text}")
        
        keywords = []
        lines = keywords_with_reasons_text.strip().split('\n')
        
        filtered_lines = [line.strip() for line in lines if line.strip()]

        for i, line in enumerate(filtered_lines):
            keyword_raw = ""
            reason = "Reason not provided by AI."
            
            if ':' in line:
                parts = line.split(':', 1)
                keyword_raw = parts[0].strip()
                reason = parts[1].strip()
            else:
                keyword_raw = line.strip()
                reason = "Reason not provided by AI."

            keyword_final = re.sub(r'^(Keyword\d+|\d+\.)\s*:\s*', '', keyword_raw, flags=re.IGNORECASE).strip()
            keyword_final = re.sub(r'^[^\w\s]*', '', keyword_final).strip()
            keyword_final = re.sub(r'[^a-zA-Z0-9\s\-/]', '', keyword_final).strip()
            keyword_final = re.sub(r'[:.]$', '', keyword_final).strip()

            if not keyword_final:
                logger.warning(f"âš ï¸ Global keyword parsing resulted in empty string: Original:'{line}', Candidate:'{keyword_raw}', Final:'{keyword_final}'")
                continue 

            if keyword_final and 2 <= len(keyword_final) <= 30:
                keywords.append({
                    "keyword": keyword_final,
                    "reason": reason,
                    "count": 30 - (len(keywords) * 5),
                    "rank": len(keywords) + 1
                })
                if len(keywords) >= 5:
                    break
            else:
                logger.warning(f"âš ï¸ Invalid global keyword parsed: Original:'{line}', Candidate:'{keyword_raw}', Final:'{keyword_final}' (Length/Condition failed)")
        
        if len(keywords) < 3:
            logger.warning("âš ï¸ Global keyword extraction failed or insufficient, using default keywords.")
            keywords = [
                {"keyword": "AI Technology", "reason": "GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ í‚¤ì›Œë“œ", "count": 25, "rank": 1},
                {"keyword": "Innovation", "reason": "GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ í‚¤ì›Œë“œ", "count": 20, "rank": 2},
                {"keyword": "Digital Transformation", "reason": "GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ í‚¤ì›Œë“œ", "count": 15, "rank": 3},
                {"keyword": "Machine Learning", "reason": "GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ í‚¤ì›Œë“œ", "count": 10, "rank": 4},
                {"keyword": "Cloud Computing", "reason": "GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ í‚¤ì›Œë“œ", "count": 5, "rank": 5}
            ]

        return keywords

    except Exception as e:
        logger.error(f"âŒ í•´ì™¸ í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
        return [
            {"keyword": "AI Tech", "reason": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ìƒ˜í”Œ ë°ì´í„°", "count": 25, "rank": 1},
            {"keyword": "Global Innovation", "reason": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ìƒ˜í”Œ ë°ì´í„°", "count": 20, "rank": 2},
            {"keyword": "Digital Future", "reason": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ìƒ˜í”Œ ë°ì´í„°", "count": 15, "rank": 3}
        ]

async def extract_keywords_with_gpt4o(articles):
    """Azure OpenAI GPT-4oë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    
    try:
        articles_text = "\n".join([
            f"ì œëª©: {article['title']}\në‚´ìš©: {article['content'][:200]}..."
            for article in articles[:50]
        ])
        
        prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•˜ê³  ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ê¸°ì‚¬ ë‚´ìš©:
{articles_text}

ìš”êµ¬ì‚¬í•­:
1. ê¸°ì—…ëª…ì€ ì œì™¸í•˜ê³  ê¸°ìˆ /ì‚°ì—… ê´€ë ¨ í‚¤ì›Œë“œ ìš°ì„  ì¶”ì¶œ
2. ê¸°ì‚¬ì—ì„œ ìì£¼ ì–¸ê¸‰ë˜ëŠ” ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
3. ì‘ë‹µ í˜•ì‹: í‚¤ì›Œë“œ1:ë¹ˆë„1, í‚¤ì›Œë“œ2:ë¹ˆë„2 (ì½¤ë§ˆ êµ¬ë¶„)
4. ë¹ˆë„ëŠ” 5-25 ë²”ìœ„
5. ìµœì†Œ 5ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ

ì£¼ìš” í‚¤ì›Œë“œ:
"""
        
        response = openai_client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=[
                {"role": "system", "content": "ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê¸°ì‚¬ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1500,
            temperature=0.2
        )
        
        keywords_text = response.choices[0].message.content or ""
        logger.info(f"GPT-4o ì‘ë‹µ: {keywords_text}")
        
        keywords = []
        for item in keywords_text.split(','):
            if ':' in item:
                parts = item.strip().split(':', 1)
                keyword = parts[0].strip()
                try:
                    count = int(parts[1].strip())
                    keywords.append({"keyword": keyword, "count": count})
                except:
                    keywords.append({"keyword": keyword, "count": 10})
        
        if not keywords:
            logger.warning("âš ï¸ GPT-4oì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©")
            keywords = [
                {"keyword": "IT", "count": 20},
                {"keyword": "ê¸°ìˆ ", "count": 18},
                {"keyword": "ë””ì§€í„¸", "count": 15},
                {"keyword": "ì •ë³´", "count": 12},
                {"keyword": "ì‹œìŠ¤í…œ", "count": 10}
            ]
        
        keywords.sort(key=lambda x: x['count'], reverse=True)
        
        logger.info(f"âœ… {len(keywords)}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
        return keywords
        
    except Exception as e:
        logger.error(f"âŒ GPT-4o ì˜¤ë¥˜: {e}")
        return []

def extract_keyword_and_industry(question: str) -> Dict[str, Any]:
    """ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œì™€ ì‚°ì—… ë¶„ë¥˜, ê·¸ë¦¬ê³  ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì„ ì • ì´ìœ ë¥¼ ì¶”ì¶œ"""
    
    industry_keywords = {
        "ì‚¬íšŒ": ["ì‚¬íšŒ", "êµìœ¡", "ì¼ìë¦¬", "ë³µì§€", "ì •ì±…", "ì œë„", "ì‹œë¯¼", "ê³µê³µ"],
        "ê²½ì œ": ["ê²½ì œ", "ì‹œì¥", "íˆ¬ì", "ê¸ˆìœµ", "ì£¼ê°€", "ë¹„ìš©", "ìˆ˜ìµ", "ë§¤ì¶œ", "ê¸°ì—…"],
        "IT/ê³¼í•™": ["ê¸°ìˆ ", "ê°œë°œ", "í˜ì‹ ", "ì—°êµ¬", "ê³¼í•™", "IT", "ì†Œí”„íŠ¸ì›¨ì–´", "í•˜ë“œì›¨ì–´", "í”Œë«í¼", "ì¸ê³µì§€ëŠ¥", "ë°˜ë„ì²´", "í´ë¼ìš°ë“œ", "ë©”íƒ€ë²„ìŠ¤", "ë¸”ë¡ì²´ì¸", "AI", "ChatGPT", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "ë¡œë´‡", "ë°ì´í„° ê³¼í•™"],
        "ìƒí™œ/ë¬¸í™”": ["ìƒí™œ", "ë¬¸í™”", "ë¼ì´í”„ìŠ¤íƒ€ì¼", "ì†Œë¹„", "íŠ¸ë Œë“œ", "ì¼ìƒ", "ì—¬ê°€", "ì—”í„°í…Œì¸ë¨¼íŠ¸", "ì˜í™”", "ìŒì•…", "ê²Œì„"],
        "ì„¸ê³„": ["ê¸€ë¡œë²Œ", "êµ­ì œ", "ì„¸ê³„", "í•´ì™¸", "ìˆ˜ì¶œ", "í˜‘ë ¥", "ê²½ìŸ", "í‘œì¤€"]
    }
    
    question_lower = question.lower()
    
    detected_industry = None
    for industry, keywords in industry_keywords.items():
        if any(keyword in question_lower for keyword in keywords):
            detected_industry = industry
            break
    
    current_keywords = get_current_weekly_keywords()
    detected_keyword = None
    
    detected_keyword_reason = None

    for keyword in current_keywords:
        if keyword in question:
            detected_keyword = keyword
            match_reason = re.search(f"(ìµœê·¼|ìƒˆë¡œìš´|ë°œì „|ì¦ê°€|í•˜ë½|ì¸í•´|ë”°ë¼|ê´€ë ¨í•˜ì—¬|ëŒ€í•´)\s*(?:{re.escape(keyword)})\s*(.*)", question)
            if match_reason:
                context_word = match_reason.group(1).strip()
                trailing_text = match_reason.group(2).strip()
                if trailing_text:
                    detected_keyword_reason = f"{context_word} {trailing_text}"[:50].strip()
                else:
                    detected_keyword_reason = f"{context_word} ì–¸ê¸‰"
            else:
                detected_keyword_reason = "ì§ˆë¬¸ ë‚´ ëª…ì‹œëœ ì´ìœ  ì—†ìŒ"
            break
        elif keyword.lower() in question_lower:
            detected_keyword = keyword
            detected_keyword_reason = "ì§ˆë¬¸ ë‚´ ê°„ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰ë¨"
            break

    question_type = "general"

    comparison_keywords = []
    if "vs" in question_lower or "ë¹„êµ" in question_lower or "ì°¨ì´" in question_lower:
        question_type = "comparison"
        comparison_keywords = [kw for kw in current_keywords if kw.lower() in question_lower]
        if not comparison_keywords and detected_keyword:
            comparison_keywords = [detected_keyword]
        
        if not comparison_keywords:
            match = re.search(r'(.+?)\s*(?:ì™€|ì™€ë„)\s*(.+?)\s*ë¹„êµ', question_lower)
            if match:
                comparison_keywords = [match.group(1).strip(), match.group(2).strip()]
            else:
                comparison_keywords = current_keywords[:2]

    elif detected_industry and detected_keyword:
        question_type = "industry_analysis"
    elif detected_keyword:
        question_type = "keyword_trend"

    return {
        "type": question_type,
        "keyword": detected_keyword,
        "keywords": comparison_keywords,
        "industry": detected_industry or "ì‚¬íšŒ",
        "reason": detected_keyword_reason
    }

def get_current_weekly_keywords():
    """í˜„ì¬ ì£¼ê°„ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°"""
    try:
        return ["ì¸ê³µì§€ëŠ¥", "ë°˜ë„ì²´", "ê¸°ìˆ í˜ì‹ "]
    except Exception as e:
        logger.error(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return ["ì¸ê³µì§€ëŠ¥", "ë°˜ë„ì²´", "ê¸°ì—…"]

async def generate_industry_based_answer(question, keyword, industry, current_keywords, reason: Optional[str] = None):
    """ì‚°ì—…ë³„/ì§ë¬´ë³„ ê´€ì  ë¶„ì„ ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
    try:
        industry_context = {
            "ì‚¬íšŒ": "ì‚¬íšŒì  ì˜í–¥, ì •ì±…ì  ì¸¡ë©´, ì‹œë¯¼ ìƒí™œ ë³€í™”",
            "ê²½ì œ": "ê²½ì œì  íŒŒê¸‰íš¨ê³¼, ì‹œì¥ ë™í–¥, íˆ¬ì ê´€ì ",
            "IT/ê³¼í•™": "ê¸°ìˆ ì  í˜ì‹ , ì—°êµ¬ê°œë°œ ë™í–¥, ê¸°ìˆ ì  ê³¼ì œ",
            "ìƒí™œ/ë¬¸í™”": "ì¼ìƒìƒí™œ ë³€í™”, ë¬¸í™”ì  ìˆ˜ìš©ì„±, ì†Œë¹„ì í–‰ë™",
            "ì„¸ê³„": "ê¸€ë¡œë²Œ íŠ¸ë Œë“œ, êµ­ì œ ê²½ìŸ, í•´ì™¸ ë™í–¥"
        }
        context_desc = industry_context.get(industry, f"'{industry}' ê´€ì ")


        reason_text = f"ì´ í‚¤ì›Œë“œëŠ” '{reason}'ì´ë¼ëŠ” êµ¬ì²´ì ì¸ ì´ìœ ë¡œ í˜„ì¬ ê°€ì¥ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤." if reason else "ì œê³µëœ ì„ ì • ì´ìœ  ì—†ìŒ."


        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±: ê° í•­ëª©ë³„ 2-3 ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ë„ë¡ ì§€ì‹œ
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ AI ë‰´ìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ í‚¤ì›Œë“œ, ê·¸ë¦¬ê³  íŠ¹ì • ì§ë¬´/ì‚°ì—… ê´€ì ì—ì„œ **ì˜¤ì§ ê¸ì •ì ì´ê³  ë‚™ê´€ì ì¸ ê´€ì **ìœ¼ë¡œ í•µì‹¬ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
        **íŠ¹íˆ, í‚¤ì›Œë“œê°€ ì„ ì •ëœ ì´ìœ ë¥¼ ëª…í™•íˆ ì´í•´í•˜ê³ , ì´ ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ì˜ í•µì‹¬ì„ ê°„ê²°í•˜ê²Œ ì „ë‹¬í•´ì£¼ì„¸ìš”.**
        
        **ë¶„ì„ ëŒ€ìƒ ì •ë³´:**
        - ì§ˆë¬¸: {question}
        - ë¶„ì„ ëŒ€ìƒ í‚¤ì›Œë“œ: {keyword}
        - í‚¤ì›Œë“œ ì„ ì • ì´ìœ : {reason_text}
        - ë¶„ì„ ê´€ì  ì§ë¬´/ì‚°ì—…: {industry} ({context_desc})
        - í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œ: {', '.join(current_keywords)}

        **ë¶„ì„ ì§€ì¹¨:**
        1. **'{industry}' ì§ë¬´/ì‚°ì—…ê³¼ '{keyword}' í‚¤ì›Œë“œì˜ ê¸ì •ì ì¸ ê¸´ë°€í•œ ì—°ê´€ì„±**ì„ í•µì‹¬ë§Œ ìš”ì•½í•˜ì—¬ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
        2. **'{reason_text}'ì„(ë¥¼) ë°°ê²½ìœ¼ë¡œ, í˜„ì¬ ìƒí™©ê³¼ ì£¼ìš” ê¸ì •ì  ë™í–¥ì˜ í•µì‹¬ë§Œ** ë¶„ì„í•˜ì‹­ì‹œì˜¤.
        3. í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œë„ ê³ ë ¤í•˜ì—¬ ë‹µë³€ì˜ ì‹œì˜ì„±ì„ ë†’ì´ë˜, **ê°„ê²°í•˜ê²Œ ì–¸ê¸‰**í•˜ì‹­ì‹œì˜¤.
        4. ì „ë¬¸ì ì´ë˜, **ë…ìê°€ 30ì´ˆ ì•ˆì— ì½ì„ ìˆ˜ ìˆë„ë¡ ë§¤ìš° ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ì–´ì¡°**ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
        5. **ì˜¤ì§ ê¸ì •ì ì´ê³  ë‚™ê´€ì ì¸ ì¸¡ë©´ë§Œ ê°•ì¡°**í•˜ì‹­ì‹œì˜¤.
        6. ë¹„íŒì , ë¶€ì •ì  ë‚´ìš©ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        7. **ê° í•­ëª©ë‹¹ 2~3ë¬¸ì¥ ì´ë‚´ë¡œ ì‘ì„±í•˜ë©°, ì „ì²´ ë‹µë³€ì€ ìµœëŒ€ 250ì(ê³µë°± í¬í•¨)ë¥¼ ë„˜ì§€ ì•Šë„ë¡** í•´ì£¼ì„¸ìš”.

        **ë‹µë³€ í˜•ì‹:**
        Â· í˜„ì¬ ìƒí™© (ì„ ì • ì´ìœ ì™€ ì—°ê³„): [2~3ë¬¸ì¥ ìš”ì•½]
        Â· ì£¼ìš” ë™í–¥ ë° ë³€í™”: [2~3ë¬¸ì¥ ìš”ì•½]
        Â· ìƒí˜¸ ê´€ê³„ ë° ìƒí˜¸ ì˜í–¥ (ê¸ì •ì  ì¸¡ë©´): [2~3ë¬¸ì¥ ìš”ì•½]
        Â· ê¸ì •ì  ì „ë§ ë° ì‹œì‚¬ì : [2~3ë¬¸ì¥ ìš”ì•½] # í•­ëª© ì´ë¦„ í†µì¼ ë° 4ê°œë¡œ ë§ì¶¤

        ë§ˆí¬ë‹¤ìš´ í—¤ë”(#) ì‚¬ìš© ê¸ˆì§€. ì¤‘ê°„ì (Â·)ê³¼ ì´ëª¨ì§€ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.
        """

        completion = openai_client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=[
                {"role": "system", "content": f"ë‹¹ì‹ ì€ '{industry}' ê´€ì ì—ì„œ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í‚¤ì›Œë“œì— ëŒ€í•´ ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” AIì…ë‹ˆë‹¤. **ì˜¤ì§ ê¸ì •ì ì´ê³  ë‚™ê´€ì ì¸ ì¸¡ë©´ë§Œ ê°•ì¡°í•˜ë©°, ë§¤ìš° ê°„ê²°í•˜ê³  í•µì‹¬ì ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.** ë§ˆí¬ë‹¤ìš´ í—¤ë”(#) ì‚¬ìš© ê¸ˆì§€. ì¤‘ê°„ì (Â·)ê³¼ ì´ëª¨ì§€ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            temperature=0.3
        )

        return completion.choices[0].message.content

    except Exception as e:
        logger.error(f"ì£„ì†¡í•©ë‹ˆë‹¤. {industry} ê´€ì ì—ì„œì˜ '{keyword}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", exc_info=True)
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. {industry} ê´€ì ì—ì„œì˜ '{keyword}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

async def generate_keyword_trend_answer(question, keyword):
    """í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ ë‹µë³€ ìƒì„±"""
    try:
        prompt = f"""
ì§ˆë¬¸: {question}
í‚¤ì›Œë“œ: {keyword}

'{keyword}'ì˜ ìµœê·¼ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¶„ì„ ë‚´ìš©:
Â· ìµœê·¼ '{keyword}' ê´€ë ¨ ì£¼ìš” ë‰´ìŠ¤ ë™í–¥
Â· ì‹œê°„ì  ë³€í™”ì™€ ë°œì „ ë°©í–¥
Â· í–¥í›„ ì „ë§ê³¼ ê´€ì‹¬ í¬ì¸íŠ¸

ë§ˆí¬ë‹¤ìš´ í—¤ë”(#) ì‚¬ìš© ê¸ˆì§€. ì¤‘ê°„ì (Â·)ê³¼ ì´ëª¨ì§€ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.
ì‹œê°„ìˆœìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ íŠ¸ë Œë“œë¥¼ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
        
        completion = openai_client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=[
                {"role": "system", "content": f"ë‹¹ì‹ ì€ '{keyword}' ë¶„ì•¼ì˜ íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìµœì‹  ë™í–¥ê³¼ ë³€í™”ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´ í—¤ë”(#) ì‚¬ìš© ê¸ˆì§€. ì¤‘ê°„ì (Â·)ê³¼ ì´ëª¨ì§€ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=16384
        )
        
        return completion.choices[0].message.content
        
    except Exception as e:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{keyword}' íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

async def generate_comparison_answer(question, keywords, perspective_role: Optional[str] = None, reason: Optional[str] = None):
    """í‚¤ì›Œë“œë“¤ì„ ë¹„êµ ë¶„ì„ ë‹µë³€ ìƒì„± (ì§ë¬´/ì‚°ì—… ê´€ì  í¬í•¨)"""
    try:
        role_context = ""
        if perspective_role:
            role_context = f"'{perspective_role}'ì˜ ê´€ì ì—ì„œ "

        reason_text = ""
        if reason and keywords:
            reason_text = f"ì°¸ê³ : ë¹„êµ ëŒ€ìƒ í‚¤ì›Œë“œ ì¤‘ '{keywords[0]}'ì€(ëŠ”) '{reason}'ì´ë¼ëŠ” êµ¬ì²´ì ì¸ ì´ìœ ë¡œ ì„ ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë§¥ë½ì„ ë¹„êµ ë¶„ì„ì— í™œìš©í•´ì£¼ì„¸ìš”."

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±: ê¸ì •ì  ë¶„ì„ì„ ì°¸ì¡°í•˜ì—¬ ë¹„íŒì  ê´€ì  ê°•í™”, ê·¸ë¦¬ê³  ê°„ê²°ì„± ê°•ì¡°
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ê¸°ìˆ /ì‚°ì—… ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í‚¤ì›Œë“œë“¤ì„ íŠ¹ì • ì§ë¬´/ì‚°ì—… ê´€ì ì—ì„œ **ë¹„íŒì ì´ê³  íšŒì˜ì ì¸ ì‹œê°**ìœ¼ë¡œ í•µì‹¬ì„ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤.
        **ì œê³µëœ ê¸ì •ì  ë¶„ì„ ë‚´ìš©ì„ ì¶©ë¶„íˆ ì°¸ê³ í•˜ë˜, ê·¸ ë‚´ìš©ì— ëŒ€í•´ ë°˜ëŒ€ ì˜ê²¬, ì ì¬ì  ë¬¸ì œì , í•œê³„ì , ë˜ëŠ” ë¶€ì •ì ì¸ ì˜í–¥ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.**
        **íŠ¹íˆ, í‚¤ì›Œë“œê°€ ì„ ì •ëœ ì´ìœ ê°€ ìˆë‹¤ë©´ ê·¸ ë§¥ë½ì„ ê¹Šì´ ì´í•´í•˜ê³  ë¹„íŒì  ë¶„ì„ì— ì ê·¹ì ìœ¼ë¡œ ë°˜ì˜í•˜ì—¬ ë‹µë³€ì˜ í•µì‹¬ë§Œ ì „ë‹¬í•´ì£¼ì„¸ìš”.**

        **ë¶„ì„ ëŒ€ìƒ ì •ë³´:**
        - ì§ˆë¬¸: {question}
        - ë¹„êµ ëŒ€ìƒ í‚¤ì›Œë“œ: {', '.join(keywords)}
        - ë¶„ì„ ê´€ì  ì§ë¬´/ì‚°ì—…: {role_context.strip()}
        {reason_text}

        **ë¶„ì„ ì§€ì¹¨:**
        1. ê° í‚¤ì›Œë“œì˜ í˜„ì¬ ìƒí™©ê³¼ íŠ¹ì§•ì„ ì„¤ëª…í•˜ë˜, **ì œê³µëœ ì„ ì • ì´ìœ (`{reason_text}`)**ê°€ ìˆë‹¤ë©´ í•´ë‹¹ í‚¤ì›Œë“œì˜ ì¤‘ìš”ì„± ì´ë©´ì— ìˆ¨ê²¨ì§„ ë¬¸ì œì ì˜ í•µì‹¬ì„ ì§€ì í•˜ì‹­ì‹œì˜¤.
        2. í‚¤ì›Œë“œì™€ '{perspective_role}' ì§ë¬´/ì‚°ì—… ê°„ì˜ **ê³µí†µì  ë° ê¸´ë°€í•œ ì—°ê´€ì„±ì„ ì¸ì •í•˜ë˜, íŠ¹íˆ ìš°ë ¤ë˜ëŠ” ì°¨ì´ì , ê°ˆë“± ìš”ì†Œ, ë˜ëŠ” í•´ê²°í•´ì•¼ í•  ê³¼ì œì˜ í•µì‹¬**ì„ ë¶„ì„í•˜ì‹­ì‹œì˜¤.
        3. í‚¤ì›Œë“œë“¤ ê°„ì˜ **ìƒí˜¸ ê´€ê³„ ë° ì„œë¡œì—ê²Œ ë¯¸ì¹˜ëŠ” ë¶€ì •ì ì¸ ì˜í–¥, ë˜ëŠ” ì˜ˆìƒì¹˜ ëª»í•œ ë¶€ì‘ìš©ì˜ í•µì‹¬**ì„ ê¸°ìˆ í•˜ì‹­ì‹œì˜¤.
        4. ê°ê°ì˜ í‚¤ì›Œë“œê°€ ê°€ì§„ **ë¯¸ë˜ì˜ ìœ„í—˜ ìš”ì†Œ, ë¶ˆí™•ì‹¤ì„±, ë˜ëŠ” ë¶€ì •ì  ì „ë§ê³¼ í˜„ì¬ì˜ ì¤‘ìš”ì„± ì´ë©´ì— ìˆ¨ê²¨ì§„ ì·¨ì•½ì ì˜ í•µì‹¬**ì„ ì œì‹œí•˜ì‹­ì‹œì˜¤.
        5. **ê°ê´€ì ì´ê³  ê· í˜• ì¡íŒ ì‹œê°ì„ ìœ ì§€í•˜ë©´ì„œë„, ë¹„íŒì ì´ê³  íšŒì˜ì ì¸ ê´€ì ì˜ í•µì‹¬**ì„ ëª…í™•íˆ ì œì‹œí•˜ì‹­ì‹œì˜¤.
        6. ë‹µë³€ì€ **ê¸ì •ì  ë¶„ì„ê³¼ ë¹„ìŠ·í•œ ë¶„ëŸ‰ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ë©°, ê° í•­ëª©ë‹¹ 2~3ë¬¸ì¥ ì´ë‚´ë¡œ ì‘ì„±, ì „ì²´ ë‹µë³€ì€ ìµœëŒ€ 250ì(ê³µë°± í¬í•¨)ë¥¼ ë„˜ì§€ ì•Šë„ë¡** í•´ì£¼ì„¸ìš”.

        **ë‹µë³€ í˜•ì‹:**
        Â· í˜„ì¬ ìƒí™© ë° íŠ¹ì§• (ê¸ì •ì  ë¶„ì„ ì°¸ì¡°í•œ ë¹„íŒì  ì„¤ëª…): [2~3ë¬¸ì¥ ìš”ì•½]
        Â· ê³µí†µì  ë° ì°¨ì´ì  (í•´ê²° ê³¼ì œ ê°•ì¡°): [2~3ë¬¸ì¥ ìš”ì•½]
        Â· ìƒí˜¸ ê´€ê³„ ë° ìƒí˜¸ ì˜í–¥ (ë¶€ì •ì  ì¸¡ë©´): [2~3ë¬¸ì¥ ìš”ì•½]
        Â· ë¯¸ë˜ ì „ë§ ë° ì¤‘ìš”ì„± (ë¹„íŒì  ì¸¡ë©´): [2~3ë¬¸ì¥ ìš”ì•½]

        ë§ˆí¬ë‹¤ìš´ í—¤ë”(#) ì‚¬ìš© ê¸ˆì§€. ì¤‘ê°„ì (Â·)ê³¼ ì´ëª¨ì§€ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.
        ê°ê´€ì ì´ê³  ê· í˜•ì¡íŒ ì‹œê°ìœ¼ë¡œ ë¹„êµí•´ì£¼ì„¸ìš”.
        """

        completion = openai_client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=[
                {"role": "system", "content": f"ë‹¹ì‹ ì€ {perspective_role or 'ê¸°ìˆ '} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ì–‘í•œ í‚¤ì›Œë“œë¥¼ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤. **ì£¼ì–´ì§„ ê¸ì •ì  ë¶„ì„ì„ ì°¸ê³ í•˜ì—¬ ë¹„íŒì ì´ê³  íšŒì˜ì ì¸ ì‹œê°ìœ¼ë¡œ í•µì‹¬ì„ ë‹µë³€í•©ë‹ˆë‹¤.** ë§ˆí¬ë‹¤ìš´ í—¤ë”(#) ì‚¬ìš© ê¸ˆì§€. ì¤‘ê°„ì (Â·)ê³¼ ì´ëª¨ì§€ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."}, 
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            temperature=0.3
        )

        return completion.choices[0].message.content

    except Exception as e:
        logger.error(f"ì£„ì†¡í•©ë‹ˆë‹¤. í‚¤ì›Œë“œ ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. í‚¤ì›Œë“œ ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

async def generate_contextual_answer(question, current_keywords):
    """í˜„ì¬ í‚¤ì›Œë“œ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¼ë°˜ ë‹µë³€ ìƒì„±"""
    try:
        keywords_context = f"í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œ: {', '.join(current_keywords)}"
        
        prompt = f"""
ì§ˆë¬¸: {question}
{keywords_context}

í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œë“¤ê³¼ ì—°ê´€ì§€ì–´ ë‹µë³€í•˜ë˜, ì§ˆë¬¸ì˜ ë§¥ë½ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€ ì‹œ ê³ ë ¤ì‚¬í•­:
Â· í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œì™€ì˜ ì—°ê´€ì„± ì–¸ê¸‰
Â· êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ë°ì´í„° í™œìš©  
Â· ê· í˜•ì¡íŒ ì‹œê°ìœ¼ë¡œ ì„¤ëª…
Â· ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ

ë§ˆí¬ë‹¤ìš´ í—¤ë”(#) ì‚¬ìš© ê¸ˆì§€. ì¤‘ê°„ì (Â·)ê³¼ ì´ëª¨ì§€ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.
ëª…í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        completion = openai_client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=[
                {"role": "system", "content": f"ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í˜„ì¬ ì£¼ê°„ í•µì‹¬ í‚¤ì›Œë“œ({', '.join(current_keywords)})ë¥¼ ê³ ë ¤í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=16384
        )
        
        return completion.choices[0].message.content
        
    except Exception as e:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def analyze_keyword_dynamically(request: dict):
    """ë™ì  í‚¤ì›Œë“œ ë¶„ì„ - í´ë¦­ëœ í‚¤ì›Œë“œì— ëŒ€í•œ ë‹¤ê°ë„ ë¶„ì„"""
    keyword = request.get("keyword", "")
    
    if not keyword:
        raise HTTPException(status_code=400, detail="í‚¤ì›Œë“œë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
    
    try:
        prompt = f"""
í‚¤ì›Œë“œ: '{keyword}'

ë‹¤ìŒ 5ê°€ì§€ ê´€ì ì—ì„œ ì´ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
Â· ì‚¬íšŒì  ì˜í–¥
Â· ê²½ì œì  ì¸¡ë©´  
Â· ê¸°ìˆ ì  ê´€ì 
Â· ë¬¸í™”ì  ì˜ë¯¸
Â· ë¯¸ë˜ ì „ë§

ê° ê´€ì ë³„ë¡œ 2-3ë¬¸ì¥ì”© ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ë§ˆí¬ë‹¤ìš´ í—¤ë”(#) ì‚¬ìš© ê¸ˆì§€. ì¤‘ê°„ì (Â·)ê³¼ ì´ëª¨ì§€ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
"""
        
        completion = openai_client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´ í—¤ë”(#) ì‚¬ìš© ê¸ˆì§€. ì¤‘ê°„ì (Â·)ê³¼ ì´ëª¨ì§€ë¡œ êµ¬ë¶„í•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1500
        )
        
        return {
            "keyword": keyword,
            "analysis": completion.choices[0].message.content
        }
        
    except Exception as e:
        return {
            "keyword": keyword,
            "analysis": f"í‚¤ì›Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }

async def generate_weekly_insight(keywords_data):
    """ì£¼ê°„ ì¸ì‚¬ì´íŠ¸ ìƒì„± (ê°œì„ ëœ êµ¬ì¡°)"""
    try:
        domestic_details = [f"{k['keyword']} ({k['count']}ê±´)" for k in keywords_data["domestic_keywords"]]
        global_details = [f"{k['keyword']} ({k['count']}ê±´)" for k in keywords_data["global_keywords"]]

        prompt = f"""
        AI ë‰´ìŠ¤ êµ¬ë…ìë“¤ì„ ìœ„í•œ ì£¼ê°„ ì¸ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ì „ë¬¸ì ì´ë©´ì„œë„ ì½ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.

        ğŸ“Š ì´ë²ˆ ì£¼ ë¶„ì„ ë°ì´í„°:
        Â· ë¶„ì„ ê¸°ê°„: {keywords_data["period"]}
        Â· êµ­ë‚´ TOP í‚¤ì›Œë“œ: {", ".join(domestic_details)}
        Â· í•´ì™¸ TOP í‚¤ì›Œë“œ: {", ".join(global_details)}

        ë‹¤ìŒ êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

        ï¿½ ì´ë²ˆ ì£¼ í•« í‚¤ì›Œë“œ

        ğŸ“ˆ êµ­ë‚´ ê¸°ìˆ  ë™í–¥
        Â· ê°€ì¥ ì£¼ëª©ë°›ì€ í‚¤ì›Œë“œì™€ ê·¸ ë°°ê²½
        Â· ê´€ë ¨ ì‚°ì—…/ê¸°ì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
        Â· ì‹¤ë¬´ì§„ì´ ì•Œì•„ì•¼ í•  í¬ì¸íŠ¸

        ğŸŒ ê¸€ë¡œë²Œ ê¸°ìˆ  íŠ¸ë Œë“œ
        Â· í•´ì™¸ì—ì„œ í™”ì œê°€ ëœ ê¸°ìˆ  ì´ìŠˆ
        Â· êµ­ë‚´ ì‹œì¥ì— ë¯¸ì¹  ì˜í–¥ ì˜ˆì¸¡
        Â· ê¸€ë¡œë²Œ vs êµ­ë‚´ íŠ¸ë Œë“œ ë¹„êµ

        ğŸ’¡ ë‹¤ìŒ ì£¼ ì „ë§ ë° ì‹¤í–‰ í¬ì¸íŠ¸
        Â· ì£¼ëª©í•´ì•¼ í•  ê¸°ìˆ /í‚¤ì›Œë“œ
        Â· ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒë‚˜ ìœ„í—˜ ìš”ì†Œ
        Â· ì‹¤ë¬´ì§„ì„ ìœ„í•œ ì•¡ì…˜ ì•„ì´í…œ

        ğŸ¯ í•œ ì¤„ ìš”ì•½
        Â· ì´ë²ˆ ì£¼ ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ

        âš ï¸ ì¤‘ìš”: ë§ˆí¬ë‹¤ìš´ í—¤ë” ê¸°í˜¸ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì´ëª¨ì§€ì™€ ì¤‘ê°„ì ë§Œ ì‚¬ìš©í•´ì„œ êµ¬ë¶„í•´ì£¼ì„¸ìš”.
        ì „ì²´ ë¶„ëŸ‰: 1000ì ë‚´ì™¸ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """

        completion = openai_client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ AI ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ê°„ ì¸ì‚¬ì´íŠ¸ë¥¼ êµ¬ë…ìë“¤ì—ê²Œ ì œê³µí•©ë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´ í—¤ë”(#) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€. ëŒ€ì‹  ì´ëª¨ì§€ì™€ ì¤‘ê°„ì (Â·)ë§Œ ì‚¬ìš©í•˜ì—¬ êµ¬ë¶„í•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1500,
            temperature=0.3
        )

        return completion.choices[0].message.content
    except Exception as e:
        logger.error(f"âŒ ì£¼ê°„ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return """
ğŸ” ì´ë²ˆ ì£¼ AI ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸

ï¿½ êµ­ë‚´ ê¸°ìˆ  íŠ¸ë Œë“œ
â€¢ ì¸ê³µì§€ëŠ¥ê³¼ ë°˜ë„ì²´ ë¶„ì•¼ì˜ ì§€ì†ì ì¸ ì„±ì¥
â€¢ ê¸°ìˆ  í˜ì‹ ê³¼ ì‚°ì—… ë³€í™” ê°€ì†í™”
â€¢ ì •ë¶€ ì •ì±…ê³¼ ê¸°ì—… íˆ¬ì í™•ëŒ€

ï¿½ ê¸€ë¡œë²Œ ê¸°ìˆ  ë™í–¥
â€¢ AI ê¸°ìˆ ì˜ ì „ ì‚°ì—… í™•ì‚°
â€¢ ê¸€ë¡œë²Œ ê¸°ìˆ  ê²½ìŸ ì‹¬í™”
â€¢ ì‹ ê¸°ìˆ  ë„ì…ê³¼ í™œìš© ì‚¬ë¡€ ì¦ê°€

ğŸ’¡ ì£¼ê°„ ì¸ì‚¬ì´íŠ¸
ì´ë²ˆ ì£¼ëŠ” AIì™€ ë°˜ë„ì²´ ê¸°ìˆ ì´ ì£¼ìš” í™”ë‘ì˜€ìŠµë‹ˆë‹¤. êµ­ë‚´ì™¸ ëª¨ë‘ ê¸°ìˆ  í˜ì‹ ì— ëŒ€í•œ ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìˆì–´ ê´€ë ¨ ì‚°ì—…ì˜ ì„±ì¥ì´ ê¸°ëŒ€ë©ë‹ˆë‹¤.

ğŸ¯ ë‹¤ìŒ ì£¼ ì „ë§
â€¢ AI ê¸°ìˆ  ë°œì „ ì§€ì† ê´€ì°° í•„ìš”
â€¢ ê´€ë ¨ íˆ¬ì ê¸°íšŒ ëª¨ë‹ˆí„°ë§ ê¶Œì¥

ğŸ“§ News GPT v2 íŒ€ ë“œë¦¼
        """


async def get_gpt_commentary(trend_request):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë Œë“œì— ëŒ€í•œ í•´ì„¤ ìƒì„±"""
    try:
        if not trend_request.headlines:
            return {"comment": "ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ì–´ íŠ¸ë Œë“œ í•´ì„¤ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "status": "no_news"}

        prompt = (
            f"The following are recent news headlines related to the keyword '{trend_request.keyword}':\n"
            + "\n".join(f"- {title}" for title in trend_request.headlines)
            + "\n\nBased on these headlines, explain why people are likely searching for this keyword.\n\n"
            "ğŸ§  Output format:\n"
            "1. A one-sentence summary of the main reason for the keyword being searched.\n"
            "2. A short paragraph elaborating on the reason, based on the headlines.\n\n"
            "ğŸ“Œ Rules:\n"
            "- All output must be in Korean.\n"
            "- Do NOT mention 'Google Trends' anywhere in the answer.\n"
            "- If the headlines are insufficient to determine a clear reason, you may use general web knowledge to supplement your explanation.\n"
            "- In that case, please add the following sentence at the end of the paragraph:\n"
            "  â€» ê¸°ì‚¬ ì œëª©ë§Œìœ¼ë¡œëŠ” ìœ ì˜ë¯¸í•œ ê²€ìƒ‰ ì›ì¸ì„ ì°¾ê¸° ì–´ë ¤ì›Œ, ì¶”ê°€ ì •ë³´ë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤."
        )
        response = openai_keyword_explainer_client.chat.completions.create(
            model=AZURE_OPENAI_KEYWORD_EXPLAINER_DEPLOYMENT,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=16384
        )

        logger.info(f"GPT Commentary Response: {response.choices[0].message.content}")
        
        return response.choices[0].message.content or "No commentary generated."
    except Exception as e:
        logger.error(f"Error generating GPT commentary: {e}", exc_info=True)
        return "Failed to generate commentary due to a server error." 